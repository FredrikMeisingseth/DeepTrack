{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unet, imageGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your network architecture\n",
    "Generates 1000 training images and 30 test images together with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\School\\Ã…rskurs 3\\Kandidat\\DeepTrack\\DeepTrack 1.0\\unet.py:60: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
      "  model = Model(input=input, output=output)\n"
     ]
    }
   ],
   "source": [
    "model = unet.create_unet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio\n",
    "\n",
    "imsize = (129,129,1)\n",
    "xbatch = np.zeros((1000, 144, 144, 1))\n",
    "ybatch = np.zeros((1000, 144, 144, 1))\n",
    "padding_tuple = imageGeneration.get_padding(imsize[0:4], 4)\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    xdata = np.zeros(imsize)\n",
    "    ydata = np.zeros(imsize)\n",
    "    xdata[:,:,0] = imageio.imread('data/particles/train/image/' + str(i) + '.png') / 255\n",
    "    xdata = np.pad(xdata,padding_tuple  + ((0,0),))\n",
    "    if(i==0):\n",
    "        plt.imshow(xdata[:,:,0], cmap='gray')\n",
    "        plt.show()\n",
    "    ydata[:,:,0] = imageio.imread('data/particles/train/label/' + str(i) + '.png') / 255\n",
    "    ydata = np.pad(ydata,padding_tuple  + ((0,0),))\n",
    "    xbatch[i,:,:,:] = xdata\n",
    "    ybatch[i,:,:,:] = ydata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trains the network on 100 epochs and saves the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5747 - accuracy: 0.9652\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.57470, saving model to unet_particle.hdf5\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0821 - accuracy: 0.9960: 0s - loss: 0.0879 - accu\n",
      "\n",
      "Epoch 00002: loss improved from 0.57470 to 0.08206, saving model to unet_particle.hdf5\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0340 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00003: loss improved from 0.08206 to 0.03399, saving model to unet_particle.hdf5\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0289 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00004: loss improved from 0.03399 to 0.02886, saving model to unet_particle.hdf5\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0279 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00005: loss improved from 0.02886 to 0.02791, saving model to unet_particle.hdf5\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0236 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00006: loss improved from 0.02791 to 0.02359, saving model to unet_particle.hdf5\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0227 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00007: loss improved from 0.02359 to 0.02274, saving model to unet_particle.hdf5\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0221 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00008: loss improved from 0.02274 to 0.02215, saving model to unet_particle.hdf5\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0217 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00009: loss improved from 0.02215 to 0.02165, saving model to unet_particle.hdf5\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0205 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00010: loss improved from 0.02165 to 0.02053, saving model to unet_particle.hdf5\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0187 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00011: loss improved from 0.02053 to 0.01868, saving model to unet_particle.hdf5\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0171 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00012: loss improved from 0.01868 to 0.01707, saving model to unet_particle.hdf5\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0156 - accuracy: 0.9966: 0s - loss: 0.0157 - accuracy: \n",
      "\n",
      "Epoch 00013: loss improved from 0.01707 to 0.01561, saving model to unet_particle.hdf5\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0145 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00014: loss improved from 0.01561 to 0.01449, saving model to unet_particle.hdf5\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0133 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00015: loss improved from 0.01449 to 0.01328, saving model to unet_particle.hdf5\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0125 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00016: loss improved from 0.01328 to 0.01255, saving model to unet_particle.hdf5\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0116 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00017: loss improved from 0.01255 to 0.01161, saving model to unet_particle.hdf5\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0107 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00018: loss improved from 0.01161 to 0.01065, saving model to unet_particle.hdf5\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0099 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00019: loss improved from 0.01065 to 0.00994, saving model to unet_particle.hdf5\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0093 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00020: loss improved from 0.00994 to 0.00933, saving model to unet_particle.hdf5\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0088 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00021: loss improved from 0.00933 to 0.00879, saving model to unet_particle.hdf5\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0084 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00022: loss improved from 0.00879 to 0.00837, saving model to unet_particle.hdf5\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0080 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00023: loss improved from 0.00837 to 0.00796, saving model to unet_particle.hdf5\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0077 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00024: loss improved from 0.00796 to 0.00771, saving model to unet_particle.hdf5\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0074 - accuracy: 0.9968: 1s - loss:\n",
      "\n",
      "Epoch 00025: loss improved from 0.00771 to 0.00735, saving model to unet_particle.hdf5\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0072 - accuracy: 0.9970\n",
      "\n",
      "Epoch 00026: loss improved from 0.00735 to 0.00719, saving model to unet_particle.hdf5\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0068 - accuracy: 0.9973\n",
      "\n",
      "Epoch 00027: loss improved from 0.00719 to 0.00682, saving model to unet_particle.hdf5\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0066 - accuracy: 0.9976: 0s - loss: 0.0066 - accura\n",
      "\n",
      "Epoch 00028: loss improved from 0.00682 to 0.00661, saving model to unet_particle.hdf5\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0063 - accuracy: 0.9979\n",
      "\n",
      "Epoch 00029: loss improved from 0.00661 to 0.00629, saving model to unet_particle.hdf5\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0060 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00030: loss improved from 0.00629 to 0.00604, saving model to unet_particle.hdf5\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00031: loss improved from 0.00604 to 0.00576, saving model to unet_particle.hdf5\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00032: loss improved from 0.00576 to 0.00552, saving model to unet_particle.hdf5\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00033: loss improved from 0.00552 to 0.00528, saving model to unet_particle.hdf5\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00034: loss improved from 0.00528 to 0.00513, saving model to unet_particle.hdf5\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0050 - accuracy: 0.9983: 0s - loss: 0.0050 \n",
      "\n",
      "Epoch 00035: loss improved from 0.00513 to 0.00499, saving model to unet_particle.hdf5\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00036: loss improved from 0.00499 to 0.00488, saving model to unet_particle.hdf5\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00037: loss improved from 0.00488 to 0.00476, saving model to unet_particle.hdf5\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00038: loss improved from 0.00476 to 0.00468, saving model to unet_particle.hdf5\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00468\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00040: loss improved from 0.00468 to 0.00454, saving model to unet_particle.hdf5\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00041: loss improved from 0.00454 to 0.00451, saving model to unet_particle.hdf5\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00042: loss improved from 0.00451 to 0.00445, saving model to unet_particle.hdf5\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss improved from 0.00445 to 0.00432, saving model to unet_particle.hdf5\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss improved from 0.00432 to 0.00431, saving model to unet_particle.hdf5\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss improved from 0.00431 to 0.00425, saving model to unet_particle.hdf5\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss improved from 0.00425 to 0.00422, saving model to unet_particle.hdf5\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00047: loss improved from 0.00422 to 0.00417, saving model to unet_particle.hdf5\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00417\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00049: loss improved from 0.00417 to 0.00416, saving model to unet_particle.hdf5\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00050: loss improved from 0.00416 to 0.00409, saving model to unet_particle.hdf5\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00051: loss improved from 0.00409 to 0.00402, saving model to unet_particle.hdf5\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00052: loss improved from 0.00402 to 0.00401, saving model to unet_particle.hdf5\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0040 - accuracy: 0.9986: 0s - loss: 0.0040 - ac\n",
      "\n",
      "Epoch 00053: loss improved from 0.00401 to 0.00399, saving model to unet_particle.hdf5\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00054: loss improved from 0.00399 to 0.00396, saving model to unet_particle.hdf5\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00055: loss improved from 0.00396 to 0.00392, saving model to unet_particle.hdf5\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00056: loss improved from 0.00392 to 0.00390, saving model to unet_particle.hdf5\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00057: loss did not improve from 0.00390\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0038 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00058: loss improved from 0.00390 to 0.00384, saving model to unet_particle.hdf5\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0039 - accuracy: 0.9986: 0s - loss: 0.0039 - accu\n",
      "\n",
      "Epoch 00059: loss did not improve from 0.00384\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0038 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00060: loss did not improve from 0.00384\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0038 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00061: loss improved from 0.00384 to 0.00381, saving model to unet_particle.hdf5\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00062: loss improved from 0.00381 to 0.00375, saving model to unet_particle.hdf5\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00063: loss improved from 0.00375 to 0.00373, saving model to unet_particle.hdf5\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00064: loss did not improve from 0.00373\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00065: loss improved from 0.00373 to 0.00371, saving model to unet_particle.hdf5\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00066: loss improved from 0.00371 to 0.00368, saving model to unet_particle.hdf5\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00067: loss improved from 0.00368 to 0.00368, saving model to unet_particle.hdf5\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00068: loss improved from 0.00368 to 0.00366, saving model to unet_particle.hdf5\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00069: loss improved from 0.00366 to 0.00365, saving model to unet_particle.hdf5\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00070: loss did not improve from 0.00365\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00071: loss improved from 0.00365 to 0.00364, saving model to unet_particle.hdf5\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00072: loss improved from 0.00364 to 0.00361, saving model to unet_particle.hdf5\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00073: loss improved from 0.00361 to 0.00359, saving model to unet_particle.hdf5\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00074: loss improved from 0.00359 to 0.00356, saving model to unet_particle.hdf5\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00075: loss did not improve from 0.00356\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00076: loss improved from 0.00356 to 0.00353, saving model to unet_particle.hdf5\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00077: loss did not improve from 0.00353\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00078: loss improved from 0.00353 to 0.00353, saving model to unet_particle.hdf5\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00079: loss did not improve from 0.00353\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00080: loss improved from 0.00353 to 0.00351, saving model to unet_particle.hdf5\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00081: loss did not improve from 0.00351\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00082: loss improved from 0.00351 to 0.00349, saving model to unet_particle.hdf5\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00083: loss did not improve from 0.00349\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00084: loss improved from 0.00349 to 0.00347, saving model to unet_particle.hdf5\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00085: loss improved from 0.00347 to 0.00346, saving model to unet_particle.hdf5\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "\n",
      "Epoch 00086: loss did not improve from 0.00346\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0034 - accuracy: 0.9988\n",
      "\n",
      "Epoch 00087: loss improved from 0.00346 to 0.00342, saving model to unet_particle.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0034 - accuracy: 0.9988\n",
      "\n",
      "Epoch 00088: loss improved from 0.00342 to 0.00342, saving model to unet_particle.hdf5\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0034 - accuracy: 0.9988\n",
      "\n",
      "Epoch 00089: loss improved from 0.00342 to 0.00342, saving model to unet_particle.hdf5\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0034 - accuracy: 0.9988\n",
      "\n",
      "Epoch 00090: loss improved from 0.00342 to 0.00339, saving model to unet_particle.hdf5\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0034 - accuracy: 0.9988\n",
      "\n",
      "Epoch 00091: loss did not improve from 0.00339\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0034 - accuracy: 0.9988\n",
      "\n",
      "Epoch 00092: loss improved from 0.00339 to 0.00337, saving model to unet_particle.hdf5\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0034 - accuracy: 0.9988\n",
      "\n",
      "Epoch 00093: loss did not improve from 0.00337\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0034 - accuracy: 0.9988\n",
      "\n",
      "Epoch 00094: loss improved from 0.00337 to 0.00337, saving model to unet_particle.hdf5\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0033 - accuracy: 0.9988\n",
      "\n",
      "Epoch 00095: loss improved from 0.00337 to 0.00335, saving model to unet_particle.hdf5\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0033 - accuracy: 0.9988: 1s -\n",
      "\n",
      "Epoch 00096: loss did not improve from 0.00335\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0034 - accuracy: 0.9988\n",
      "\n",
      "Epoch 00097: loss did not improve from 0.00335\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0033 - accuracy: 0.9988\n",
      "\n",
      "Epoch 00098: loss improved from 0.00335 to 0.00335, saving model to unet_particle.hdf5\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0034 - accuracy: 0.9988\n",
      "\n",
      "Epoch 00099: loss did not improve from 0.00335\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0033 - accuracy: 0.9988\n",
      "\n",
      "Epoch 00100: loss improved from 0.00335 to 0.00333, saving model to unet_particle.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20a11135a88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "model_checkpoint = ModelCheckpoint('unet_particle.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "model.fit(xbatch,ybatch, epochs = 100, callbacks = [model_checkpoint])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trains the network using a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.6948 - accuracy: 0.7424\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.69480, saving model to unet_particle.hdf5\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.6926 - accuracy: 0.9154\n",
      "\n",
      "Epoch 00002: loss improved from 0.69480 to 0.69260, saving model to unet_particle.hdf5\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.6916 - accuracy: 0.9383\n",
      "\n",
      "Epoch 00003: loss improved from 0.69260 to 0.69159, saving model to unet_particle.hdf5\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.6907 - accuracy: 0.9609\n",
      "\n",
      "Epoch 00004: loss improved from 0.69159 to 0.69068, saving model to unet_particle.hdf5\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.6898 - accuracy: 0.9750\n",
      "\n",
      "Epoch 00005: loss improved from 0.69068 to 0.68981, saving model to unet_particle.hdf5\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.6890 - accuracy: 0.9840\n",
      "\n",
      "Epoch 00006: loss improved from 0.68981 to 0.68895, saving model to unet_particle.hdf5\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.6881 - accuracy: 0.9893\n",
      "\n",
      "Epoch 00007: loss improved from 0.68895 to 0.68808, saving model to unet_particle.hdf5\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.6872 - accuracy: 0.9924\n",
      "\n",
      "Epoch 00008: loss improved from 0.68808 to 0.68716, saving model to unet_particle.hdf5\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.6852 - accuracy: 0.9933\n",
      "\n",
      "Epoch 00009: loss improved from 0.68716 to 0.68523, saving model to unet_particle.hdf5\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.3674 - accuracy: 0.9457\n",
      "\n",
      "Epoch 00010: loss improved from 0.68523 to 0.36741, saving model to unet_particle.hdf5\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0799 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00011: loss improved from 0.36741 to 0.07995, saving model to unet_particle.hdf5\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0462 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00012: loss improved from 0.07995 to 0.04620, saving model to unet_particle.hdf5\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0343 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00013: loss improved from 0.04620 to 0.03432, saving model to unet_particle.hdf5\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0290 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00014: loss improved from 0.03432 to 0.02896, saving model to unet_particle.hdf5\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0263 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00015: loss improved from 0.02896 to 0.02628, saving model to unet_particle.hdf5\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0245 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00016: loss improved from 0.02628 to 0.02449, saving model to unet_particle.hdf5\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0234 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00017: loss improved from 0.02449 to 0.02341, saving model to unet_particle.hdf5\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0229 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00018: loss improved from 0.02341 to 0.02290, saving model to unet_particle.hdf5\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0224 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00019: loss improved from 0.02290 to 0.02240, saving model to unet_particle.hdf5\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0223 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00020: loss improved from 0.02240 to 0.02228, saving model to unet_particle.hdf5\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0221 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00021: loss improved from 0.02228 to 0.02215, saving model to unet_particle.hdf5\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0221 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00022: loss improved from 0.02215 to 0.02207, saving model to unet_particle.hdf5\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0219 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00023: loss improved from 0.02207 to 0.02190, saving model to unet_particle.hdf5\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0219 - accuracy: 0.9965: 1s - los\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.02190\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0218 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00025: loss improved from 0.02190 to 0.02178, saving model to unet_particle.hdf5\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0217 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00026: loss improved from 0.02178 to 0.02173, saving model to unet_particle.hdf5\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0217 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00027: loss improved from 0.02173 to 0.02173, saving model to unet_particle.hdf5\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0217 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00028: loss improved from 0.02173 to 0.02170, saving model to unet_particle.hdf5\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0216 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00029: loss improved from 0.02170 to 0.02159, saving model to unet_particle.hdf5\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0216 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.02159\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0215 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00031: loss improved from 0.02159 to 0.02154, saving model to unet_particle.hdf5\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0215 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00032: loss improved from 0.02154 to 0.02151, saving model to unet_particle.hdf5\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0214 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00033: loss improved from 0.02151 to 0.02142, saving model to unet_particle.hdf5\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0214 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00034: loss improved from 0.02142 to 0.02140, saving model to unet_particle.hdf5\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0214 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.02140\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0213 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00036: loss improved from 0.02140 to 0.02131, saving model to unet_particle.hdf5\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0214 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.02131\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0213 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00038: loss improved from 0.02131 to 0.02128, saving model to unet_particle.hdf5\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0212 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00039: loss improved from 0.02128 to 0.02121, saving model to unet_particle.hdf5\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0212 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00040: loss improved from 0.02121 to 0.02115, saving model to unet_particle.hdf5\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0211 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00041: loss improved from 0.02115 to 0.02111, saving model to unet_particle.hdf5\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0211 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00042: loss improved from 0.02111 to 0.02106, saving model to unet_particle.hdf5\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0211 - accuracy: 0.9965: 1s - los\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.02106\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0210 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00044: loss improved from 0.02106 to 0.02102, saving model to unet_particle.hdf5\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0211 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.02102\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0211 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.02102\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0210 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00047: loss improved from 0.02102 to 0.02099, saving model to unet_particle.hdf5\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0210 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00048: loss improved from 0.02099 to 0.02096, saving model to unet_particle.hdf5\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0209 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00049: loss improved from 0.02096 to 0.02091, saving model to unet_particle.hdf5\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0211 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.02091\n",
      "Iteration is 1\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0207 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00001: loss improved from 0.02091 to 0.02069, saving model to unet_particle.hdf5\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0207 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00002: loss improved from 0.02069 to 0.02069, saving model to unet_particle.hdf5\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0207 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00003: loss improved from 0.02069 to 0.02065, saving model to unet_particle.hdf5\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0206 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00004: loss improved from 0.02065 to 0.02064, saving model to unet_particle.hdf5\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0206 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00005: loss improved from 0.02064 to 0.02060, saving model to unet_particle.hdf5\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0206 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.02060\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0206 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.02060\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0206 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00008: loss improved from 0.02060 to 0.02056, saving model to unet_particle.hdf5\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0206 - accuracy: 0.9966: 1s - los\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.02056\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0206 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00010: loss improved from 0.02056 to 0.02056, saving model to unet_particle.hdf5\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0206 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.02056\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0206 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.02056\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0205 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00013: loss improved from 0.02056 to 0.02048, saving model to unet_particle.hdf5\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0205 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.02048\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0205 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.02048\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0204 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00016: loss improved from 0.02048 to 0.02041, saving model to unet_particle.hdf5\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0204 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.02041\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0204 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00018: loss improved from 0.02041 to 0.02040, saving model to unet_particle.hdf5\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0205 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.02040\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0204 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00020: loss improved from 0.02040 to 0.02036, saving model to unet_particle.hdf5\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0204 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.02036\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0203 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00022: loss improved from 0.02036 to 0.02034, saving model to unet_particle.hdf5\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0203 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00023: loss improved from 0.02034 to 0.02032, saving model to unet_particle.hdf5\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0206 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.02032\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0205 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.02032\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0203 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00026: loss improved from 0.02032 to 0.02031, saving model to unet_particle.hdf5\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0203 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00027: loss improved from 0.02031 to 0.02029, saving model to unet_particle.hdf5\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0202 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00028: loss improved from 0.02029 to 0.02019, saving model to unet_particle.hdf5\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0202 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00029: loss improved from 0.02019 to 0.02017, saving model to unet_particle.hdf5\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0201 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00030: loss improved from 0.02017 to 0.02012, saving model to unet_particle.hdf5\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0201 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00031: loss improved from 0.02012 to 0.02005, saving model to unet_particle.hdf5\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0201 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.02005\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0201 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.02005\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0203 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.02005\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0199 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00035: loss improved from 0.02005 to 0.01995, saving model to unet_particle.hdf5\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0199 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00036: loss improved from 0.01995 to 0.01988, saving model to unet_particle.hdf5\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0198 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00037: loss improved from 0.01988 to 0.01983, saving model to unet_particle.hdf5\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0197 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00038: loss improved from 0.01983 to 0.01971, saving model to unet_particle.hdf5\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0197 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.01971\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0197 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00040: loss improved from 0.01971 to 0.01971, saving model to unet_particle.hdf5\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0197 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.01971\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0194 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00042: loss improved from 0.01971 to 0.01938, saving model to unet_particle.hdf5\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0193 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00043: loss improved from 0.01938 to 0.01925, saving model to unet_particle.hdf5\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0191 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00044: loss improved from 0.01925 to 0.01907, saving model to unet_particle.hdf5\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0189 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00045: loss improved from 0.01907 to 0.01890, saving model to unet_particle.hdf5\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0185 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00046: loss improved from 0.01890 to 0.01851, saving model to unet_particle.hdf5\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0181 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00047: loss improved from 0.01851 to 0.01811, saving model to unet_particle.hdf5\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0176 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00048: loss improved from 0.01811 to 0.01765, saving model to unet_particle.hdf5\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0171 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00049: loss improved from 0.01765 to 0.01715, saving model to unet_particle.hdf5\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0170 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00050: loss improved from 0.01715 to 0.01704, saving model to unet_particle.hdf5\n",
      "Iteration is 2\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0166 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00001: loss improved from 0.01704 to 0.01660, saving model to unet_particle.hdf5\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0156 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00002: loss improved from 0.01660 to 0.01555, saving model to unet_particle.hdf5\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0149 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00003: loss improved from 0.01555 to 0.01489, saving model to unet_particle.hdf5\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0141 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00004: loss improved from 0.01489 to 0.01409, saving model to unet_particle.hdf5\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0135 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00005: loss improved from 0.01409 to 0.01352, saving model to unet_particle.hdf5\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0129 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00006: loss improved from 0.01352 to 0.01289, saving model to unet_particle.hdf5\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0124 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00007: loss improved from 0.01289 to 0.01236, saving model to unet_particle.hdf5\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0120 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00008: loss improved from 0.01236 to 0.01199, saving model to unet_particle.hdf5\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0115 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00009: loss improved from 0.01199 to 0.01150, saving model to unet_particle.hdf5\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0112 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00010: loss improved from 0.01150 to 0.01123, saving model to unet_particle.hdf5\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0108 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00011: loss improved from 0.01123 to 0.01079, saving model to unet_particle.hdf5\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0104 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00012: loss improved from 0.01079 to 0.01042, saving model to unet_particle.hdf5\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0103 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00013: loss improved from 0.01042 to 0.01029, saving model to unet_particle.hdf5\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0100 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00014: loss improved from 0.01029 to 0.01001, saving model to unet_particle.hdf5\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0097 - accuracy: 0.9963\n",
      "\n",
      "Epoch 00015: loss improved from 0.01001 to 0.00973, saving model to unet_particle.hdf5\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0095 - accuracy: 0.9964\n",
      "\n",
      "Epoch 00016: loss improved from 0.00973 to 0.00949, saving model to unet_particle.hdf5\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0094 - accuracy: 0.9964\n",
      "\n",
      "Epoch 00017: loss improved from 0.00949 to 0.00943, saving model to unet_particle.hdf5\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0092 - accuracy: 0.9964\n",
      "\n",
      "Epoch 00018: loss improved from 0.00943 to 0.00919, saving model to unet_particle.hdf5\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0090 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00019: loss improved from 0.00919 to 0.00905, saving model to unet_particle.hdf5\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0089 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00020: loss improved from 0.00905 to 0.00889, saving model to unet_particle.hdf5\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0088 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00021: loss improved from 0.00889 to 0.00877, saving model to unet_particle.hdf5\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0087 - accuracy: 0.9965\n",
      "\n",
      "Epoch 00022: loss improved from 0.00877 to 0.00869, saving model to unet_particle.hdf5\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0085 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00023: loss improved from 0.00869 to 0.00852, saving model to unet_particle.hdf5\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0084 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00024: loss improved from 0.00852 to 0.00843, saving model to unet_particle.hdf5\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0084 - accuracy: 0.9966\n",
      "\n",
      "Epoch 00025: loss improved from 0.00843 to 0.00835, saving model to unet_particle.hdf5\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0083 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00026: loss improved from 0.00835 to 0.00826, saving model to unet_particle.hdf5\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0082 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00027: loss improved from 0.00826 to 0.00823, saving model to unet_particle.hdf5\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0082 - accuracy: 0.9968\n",
      "\n",
      "Epoch 00028: loss improved from 0.00823 to 0.00822, saving model to unet_particle.hdf5\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0081 - accuracy: 0.9968\n",
      "\n",
      "Epoch 00029: loss improved from 0.00822 to 0.00809, saving model to unet_particle.hdf5\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0080 - accuracy: 0.9969\n",
      "\n",
      "Epoch 00030: loss improved from 0.00809 to 0.00800, saving model to unet_particle.hdf5\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0079 - accuracy: 0.9970\n",
      "\n",
      "Epoch 00031: loss improved from 0.00800 to 0.00790, saving model to unet_particle.hdf5\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0079 - accuracy: 0.9972\n",
      "\n",
      "Epoch 00032: loss improved from 0.00790 to 0.00785, saving model to unet_particle.hdf5\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0078 - accuracy: 0.9973\n",
      "\n",
      "Epoch 00033: loss improved from 0.00785 to 0.00778, saving model to unet_particle.hdf5\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0077 - accuracy: 0.9975\n",
      "\n",
      "Epoch 00034: loss improved from 0.00778 to 0.00773, saving model to unet_particle.hdf5\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0076 - accuracy: 0.9976\n",
      "\n",
      "Epoch 00035: loss improved from 0.00773 to 0.00764, saving model to unet_particle.hdf5\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0076 - accuracy: 0.9976\n",
      "\n",
      "Epoch 00036: loss improved from 0.00764 to 0.00764, saving model to unet_particle.hdf5\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0075 - accuracy: 0.9976\n",
      "\n",
      "Epoch 00037: loss improved from 0.00764 to 0.00746, saving model to unet_particle.hdf5\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0074 - accuracy: 0.9977\n",
      "\n",
      "Epoch 00038: loss improved from 0.00746 to 0.00737, saving model to unet_particle.hdf5\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0074 - accuracy: 0.9976\n",
      "\n",
      "Epoch 00039: loss improved from 0.00737 to 0.00737, saving model to unet_particle.hdf5\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0072 - accuracy: 0.9977\n",
      "\n",
      "Epoch 00040: loss improved from 0.00737 to 0.00720, saving model to unet_particle.hdf5\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0071 - accuracy: 0.9977\n",
      "\n",
      "Epoch 00041: loss improved from 0.00720 to 0.00713, saving model to unet_particle.hdf5\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0071 - accuracy: 0.9977\n",
      "\n",
      "Epoch 00042: loss improved from 0.00713 to 0.00708, saving model to unet_particle.hdf5\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0070 - accuracy: 0.9977\n",
      "\n",
      "Epoch 00043: loss improved from 0.00708 to 0.00698, saving model to unet_particle.hdf5\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0069 - accuracy: 0.9977\n",
      "\n",
      "Epoch 00044: loss improved from 0.00698 to 0.00689, saving model to unet_particle.hdf5\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0068 - accuracy: 0.9978\n",
      "\n",
      "Epoch 00045: loss improved from 0.00689 to 0.00682, saving model to unet_particle.hdf5\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0068 - accuracy: 0.9978\n",
      "\n",
      "Epoch 00046: loss improved from 0.00682 to 0.00678, saving model to unet_particle.hdf5\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0069 - accuracy: 0.9978\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00678\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0068 - accuracy: 0.9978\n",
      "\n",
      "Epoch 00048: loss improved from 0.00678 to 0.00678, saving model to unet_particle.hdf5\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0066 - accuracy: 0.9978\n",
      "\n",
      "Epoch 00049: loss improved from 0.00678 to 0.00664, saving model to unet_particle.hdf5\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0066 - accuracy: 0.9978\n",
      "\n",
      "Epoch 00050: loss improved from 0.00664 to 0.00664, saving model to unet_particle.hdf5\n",
      "Iteration is 3\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0068 - accuracy: 0.9979\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00664\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0067 - accuracy: 0.9979\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00664\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0066 - accuracy: 0.9979\n",
      "\n",
      "Epoch 00003: loss improved from 0.00664 to 0.00660, saving model to unet_particle.hdf5\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0065 - accuracy: 0.9979: 0s - loss: 0.0065 - accuracy: \n",
      "\n",
      "Epoch 00004: loss improved from 0.00660 to 0.00652, saving model to unet_particle.hdf5\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0065 - accuracy: 0.9979\n",
      "\n",
      "Epoch 00005: loss improved from 0.00652 to 0.00646, saving model to unet_particle.hdf5\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0064 - accuracy: 0.9979\n",
      "\n",
      "Epoch 00006: loss improved from 0.00646 to 0.00641, saving model to unet_particle.hdf5\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0064 - accuracy: 0.9979\n",
      "\n",
      "Epoch 00007: loss improved from 0.00641 to 0.00639, saving model to unet_particle.hdf5\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0063 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00008: loss improved from 0.00639 to 0.00633, saving model to unet_particle.hdf5\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0063 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00009: loss improved from 0.00633 to 0.00626, saving model to unet_particle.hdf5\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0062 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00010: loss improved from 0.00626 to 0.00621, saving model to unet_particle.hdf5\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0063 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00621\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0062 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00621\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0062 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00013: loss improved from 0.00621 to 0.00619, saving model to unet_particle.hdf5\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00014: loss improved from 0.00619 to 0.00613, saving model to unet_particle.hdf5\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00015: loss improved from 0.00613 to 0.00609, saving model to unet_particle.hdf5\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00016: loss improved from 0.00609 to 0.00608, saving model to unet_particle.hdf5\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0060 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00017: loss improved from 0.00608 to 0.00604, saving model to unet_particle.hdf5\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0060 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00018: loss improved from 0.00604 to 0.00603, saving model to unet_particle.hdf5\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0060 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00019: loss improved from 0.00603 to 0.00599, saving model to unet_particle.hdf5\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0060 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00020: loss improved from 0.00599 to 0.00597, saving model to unet_particle.hdf5\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0059 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00021: loss improved from 0.00597 to 0.00593, saving model to unet_particle.hdf5\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0059 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00593\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0059 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00023: loss improved from 0.00593 to 0.00590, saving model to unet_particle.hdf5\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0059 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00590\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0059 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00025: loss improved from 0.00590 to 0.00587, saving model to unet_particle.hdf5\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00026: loss improved from 0.00587 to 0.00584, saving model to unet_particle.hdf5\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00027: loss improved from 0.00584 to 0.00578, saving model to unet_particle.hdf5\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00578\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00578\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00578\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00031: loss improved from 0.00578 to 0.00573, saving model to unet_particle.hdf5\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00032: loss improved from 0.00573 to 0.00570, saving model to unet_particle.hdf5\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00033: loss improved from 0.00570 to 0.00566, saving model to unet_particle.hdf5\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00566\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00035: loss improved from 0.00566 to 0.00564, saving model to unet_particle.hdf5\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00036: loss improved from 0.00564 to 0.00563, saving model to unet_particle.hdf5\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00563\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00038: loss improved from 0.00563 to 0.00561, saving model to unet_particle.hdf5\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00039: loss improved from 0.00561 to 0.00558, saving model to unet_particle.hdf5\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00558\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00041: loss improved from 0.00558 to 0.00551, saving model to unet_particle.hdf5\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00551\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00551\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00551\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00551\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00046: loss improved from 0.00551 to 0.00550, saving model to unet_particle.hdf5\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00047: loss improved from 0.00550 to 0.00546, saving model to unet_particle.hdf5\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00048: loss improved from 0.00546 to 0.00546, saving model to unet_particle.hdf5\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00049: loss improved from 0.00546 to 0.00543, saving model to unet_particle.hdf5\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00543\n",
      "Iteration is 4\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0063 - accuracy: 0.9979\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00543\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00543\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00543\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00543\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00543\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00543\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0060 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00543\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0060 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00543\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0059 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00543\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0059 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00543\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0059 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00543\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0059 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00543\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0059 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00543\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0059 - accuracy: 0.9980\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00543\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0059 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00543\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00543\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00543\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00543\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00543\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00543\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00543\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00543\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00543\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00543\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00543\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00543\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00543\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00543\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00543\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00543\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00543\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00543\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00543\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00543\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00543\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00543\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00543\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00543\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00543\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00543\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00543\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00543\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00543\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00543\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00543\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00543\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00543\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981: 1s - los\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00543\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00543\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00543\n",
      "Iteration is 5\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0059 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00543\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0059 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00543\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00543\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0059 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00543\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00543\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00543\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00543\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00543\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00543\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00543\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00543\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00543\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00543\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00543\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00543\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00543\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00543\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00543\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00543\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00543\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00543\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00543\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00543\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00543\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00543\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00543\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00543\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00543\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00543\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00543\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00543\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00543\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00543\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00034: loss improved from 0.00543 to 0.00542, saving model to unet_particle.hdf5\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00542\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00542\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00037: loss improved from 0.00542 to 0.00542, saving model to unet_particle.hdf5\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00038: loss improved from 0.00542 to 0.00541, saving model to unet_particle.hdf5\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00039: loss improved from 0.00541 to 0.00538, saving model to unet_particle.hdf5\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00040: loss improved from 0.00538 to 0.00537, saving model to unet_particle.hdf5\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00041: loss improved from 0.00537 to 0.00536, saving model to unet_particle.hdf5\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00536\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00043: loss improved from 0.00536 to 0.00531, saving model to unet_particle.hdf5\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00531\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00045: loss improved from 0.00531 to 0.00531, saving model to unet_particle.hdf5\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00531\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00531\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00531\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00049: loss improved from 0.00531 to 0.00530, saving model to unet_particle.hdf5\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00050: loss improved from 0.00530 to 0.00529, saving model to unet_particle.hdf5\n",
      "Iteration is 6\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00529\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00529\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00529\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00529\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00529\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00529\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00529\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00529\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00529\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00529\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00529\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00012: loss improved from 0.00529 to 0.00527, saving model to unet_particle.hdf5\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00527\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00014: loss improved from 0.00527 to 0.00525, saving model to unet_particle.hdf5\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00525\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00016: loss improved from 0.00525 to 0.00525, saving model to unet_particle.hdf5\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00017: loss improved from 0.00525 to 0.00522, saving model to unet_particle.hdf5\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00522\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00522\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982: 1s - los\n",
      "\n",
      "Epoch 00020: loss improved from 0.00522 to 0.00519, saving model to unet_particle.hdf5\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00021: loss improved from 0.00519 to 0.00519, saving model to unet_particle.hdf5\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00022: loss improved from 0.00519 to 0.00516, saving model to unet_particle.hdf5\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00516\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00024: loss improved from 0.00516 to 0.00515, saving model to unet_particle.hdf5\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00025: loss improved from 0.00515 to 0.00511, saving model to unet_particle.hdf5\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00511\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00027: loss improved from 0.00511 to 0.00510, saving model to unet_particle.hdf5\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00028: loss improved from 0.00510 to 0.00510, saving model to unet_particle.hdf5\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00029: loss improved from 0.00510 to 0.00508, saving model to unet_particle.hdf5\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00508\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00508\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00032: loss improved from 0.00508 to 0.00507, saving model to unet_particle.hdf5\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00033: loss improved from 0.00507 to 0.00505, saving model to unet_particle.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00034: loss improved from 0.00505 to 0.00503, saving model to unet_particle.hdf5\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00035: loss improved from 0.00503 to 0.00500, saving model to unet_particle.hdf5\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00500\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00500\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00500\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00500\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00500\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00041: loss improved from 0.00500 to 0.00499, saving model to unet_particle.hdf5\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00042: loss improved from 0.00499 to 0.00498, saving model to unet_particle.hdf5\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00043: loss improved from 0.00498 to 0.00497, saving model to unet_particle.hdf5\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00044: loss improved from 0.00497 to 0.00496, saving model to unet_particle.hdf5\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00045: loss improved from 0.00496 to 0.00494, saving model to unet_particle.hdf5\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00494\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00494\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00048: loss improved from 0.00494 to 0.00492, saving model to unet_particle.hdf5\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00492\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00050: loss improved from 0.00492 to 0.00489, saving model to unet_particle.hdf5\n",
      "Iteration is 7\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00489\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00489\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00489\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00489\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00489\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00489\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00489\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00489\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00489\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0056 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00489\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00489\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00489\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00489\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00489\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00489\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00489\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00489\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00489\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00489\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00489\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00489\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00489\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00489\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00489\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00489\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00489\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00489\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00489\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00489\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00489\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00489\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00489\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00489\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00489\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00489\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00489\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00489\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00489\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00489\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00489\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00489\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00489\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00489\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00489\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00489\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00489\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00489\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00489\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00489\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00489\n",
      "Iteration is 8\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00489\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00489\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00489\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00489\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00489\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00489\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00489\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00489\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00489\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00489\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00489\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00489\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00489\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00489\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00489\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00489\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00489\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00489\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00489\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00489\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00489\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00489\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00489\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00489\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00489\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00489\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00489\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00489\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00489\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00489\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00489\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00489\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00489\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00489\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00489\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00489\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00489\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00489\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00489\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00489\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00489\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00489\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00044: loss improved from 0.00489 to 0.00488, saving model to unet_particle.hdf5\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00045: loss improved from 0.00488 to 0.00486, saving model to unet_particle.hdf5\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00046: loss improved from 0.00486 to 0.00484, saving model to unet_particle.hdf5\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00047: loss improved from 0.00484 to 0.00483, saving model to unet_particle.hdf5\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00483\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00483\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00050: loss improved from 0.00483 to 0.00481, saving model to unet_particle.hdf5\n",
      "Iteration is 9\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.99 - 2s 4ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00481\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00481\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00481\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00481\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00481\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00481\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984: 1s - loss: 0.0\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00481\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00481\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00481\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00010: loss improved from 0.00481 to 0.00478, saving model to unet_particle.hdf5\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00011: loss improved from 0.00478 to 0.00478, saving model to unet_particle.hdf5\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00478\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss improved from 0.00478 to 0.00476, saving model to unet_particle.hdf5\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss improved from 0.00476 to 0.00476, saving model to unet_particle.hdf5\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00015: loss improved from 0.00476 to 0.00474, saving model to unet_particle.hdf5\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss improved from 0.00474 to 0.00471, saving model to unet_particle.hdf5\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00471\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss improved from 0.00471 to 0.00469, saving model to unet_particle.hdf5\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00469\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00020: loss improved from 0.00469 to 0.00466, saving model to unet_particle.hdf5\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00466\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss improved from 0.00466 to 0.00465, saving model to unet_particle.hdf5\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00023: loss improved from 0.00465 to 0.00465, saving model to unet_particle.hdf5\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00024: loss improved from 0.00465 to 0.00465, saving model to unet_particle.hdf5\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00025: loss improved from 0.00465 to 0.00464, saving model to unet_particle.hdf5\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00026: loss improved from 0.00464 to 0.00459, saving model to unet_particle.hdf5\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00459\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00028: loss improved from 0.00459 to 0.00459, saving model to unet_particle.hdf5\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00029: loss improved from 0.00459 to 0.00457, saving model to unet_particle.hdf5\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00457\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00031: loss improved from 0.00457 to 0.00457, saving model to unet_particle.hdf5\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00032: loss improved from 0.00457 to 0.00455, saving model to unet_particle.hdf5\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00033: loss improved from 0.00455 to 0.00454, saving model to unet_particle.hdf5\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00454\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00035: loss improved from 0.00454 to 0.00454, saving model to unet_particle.hdf5\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00036: loss improved from 0.00454 to 0.00453, saving model to unet_particle.hdf5\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00453\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00038: loss improved from 0.00453 to 0.00448, saving model to unet_particle.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss improved from 0.00448 to 0.00448, saving model to unet_particle.hdf5\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00448\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00448\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00448\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss improved from 0.00448 to 0.00446, saving model to unet_particle.hdf5\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss improved from 0.00446 to 0.00444, saving model to unet_particle.hdf5\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss improved from 0.00444 to 0.00442, saving model to unet_particle.hdf5\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss improved from 0.00442 to 0.00441, saving model to unet_particle.hdf5\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00441\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00441\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00441\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00050: loss improved from 0.00441 to 0.00440, saving model to unet_particle.hdf5\n",
      "Iteration is 10\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00440\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00440\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00440\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00440\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00440\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00440\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00440\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00440\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983: 1s - loss: 0.0\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00440\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00440\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983: 0s - loss: 0.0050 - accuracy\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00440\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00440\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00440\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00440\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00440\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00440\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00440\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00440\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00440\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00440\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00440\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00440\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00440\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00440\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00440\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00440\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00440\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00440\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00440\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00440\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00440\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00440\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00440\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00440\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00440\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00440\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00440\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00440\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00440\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00440\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00440\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00440\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00440\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00440\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00440\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00440\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00440\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00440\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00440\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00440\n",
      "Iteration is 11\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00440\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00440\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00440\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00440\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00440\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00440\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00440\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00440\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00440\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00440\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00440\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00440\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00440\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00440\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00440\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00440\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00440\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00440\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00440\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00440\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00440\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00440\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00440\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00440\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00440\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00440\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00440\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00440\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00440\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00440\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00440\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00440\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00440\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00440\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00440\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00440\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00440\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00440\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00440\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00440\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00440\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00440\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00440\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00440\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00440\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00440\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00440\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00440\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00440\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00440\n",
      "Iteration is 12\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00440\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00440\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00440\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00440\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00440\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00440\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00440\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00440\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00440\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00440\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00440\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00440\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00440\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00440\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00440\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00440\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00440\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00440\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00440\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00440\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00440\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00440\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00440\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00440\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00440\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00440\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00440\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00440\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00440\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00440\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00440\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00440\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00440\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00440\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00440\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00440\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00440\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00440\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00440\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00440\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00440\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00440\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00440\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00440\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00440\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00440\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00440\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00440\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00440\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00440\n",
      "Iteration is 13\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0053 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00440\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00440\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00440\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00440\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00440\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00440\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00440\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00440\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00440\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00440\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00440\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00440\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00440\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00440\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00440\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00440\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00440\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00440\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00440\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00440\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00440\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00440\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00440\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00440\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00440\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00440\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00440\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00440\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00440\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00440\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00440\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00440\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00440\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00440\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00440\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00440\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00440\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00440\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00440\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00440\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00440\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00440\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00440\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00440\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00440\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00440\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00440\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00440\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00440\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00440\n",
      "Iteration is 14\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00440\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0055 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00440\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00440\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00440\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00440\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00440\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00440\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00440\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00440\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00440\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00440\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00440\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00440\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00440\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00440\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00440\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00440\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00440\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00440\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00440\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00440\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00440\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00440\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00440\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00440\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00440\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00440\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00440\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00440\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00440\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00440\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00440\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00440\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00440\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00440\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00440\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00440\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00440\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00440\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00440\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00440\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00440\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00440\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00440\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00440\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00440\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00440\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00440\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00440\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00440\n",
      "Iteration is 15\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00440\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00440\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00440\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00440\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00440\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00440\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00440\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00440\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00440\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00440\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00440\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00440\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00440\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00440\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00440\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00440\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00440\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00440\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00440\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00440\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00440\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00440\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00440\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00440\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00440\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00440\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00440\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00440\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00440\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00440\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00440\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00440\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00440\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00440\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00440\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00440\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00440\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00038: loss improved from 0.00440 to 0.00439, saving model to unet_particle.hdf5\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00439\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00040: loss improved from 0.00439 to 0.00436, saving model to unet_particle.hdf5\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00436\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00042: loss improved from 0.00436 to 0.00435, saving model to unet_particle.hdf5\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00435\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00435\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00045: loss improved from 0.00435 to 0.00434, saving model to unet_particle.hdf5\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00434\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00047: loss improved from 0.00434 to 0.00432, saving model to unet_particle.hdf5\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00048: loss improved from 0.00432 to 0.00428, saving model to unet_particle.hdf5\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00428\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00050: loss improved from 0.00428 to 0.00427, saving model to unet_particle.hdf5\n",
      "Iteration is 16\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00427\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00427\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00427\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00427\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00427\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00427\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00427\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00427\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00427\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00427\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00427\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00427\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00427\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00427\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00427\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00427\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00427\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00427\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00427\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00427\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00427\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00427\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00427\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00427\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00427\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983: 0s - loss: 0.0047 - accuracy: \n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00427\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00427\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00427\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00427\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00427\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00427\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00427\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00427\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00427\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00427\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00427\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00427\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00427\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00427\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00427\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00427\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00427\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00427\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00427\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00427\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00427\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00427\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00427\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00427\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00427\n",
      "Iteration is 17\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00427\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00427\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00427\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00427\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00427\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00427\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00427\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00427\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00427\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00427\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00427\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00427\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00427\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00427\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00427\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00427\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00427\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00427\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00427\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00427\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00427\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00427\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00427\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00427\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00427\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00427\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00427\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00427\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00427\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00427\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00427\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00427\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00427\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00427\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00427\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00427\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00427\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00427\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00427\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00427\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00427\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00427\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00427\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00427\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00427\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00427\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00427\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00427\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00427\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00427\n",
      "Iteration is 18\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00427\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00427\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00427\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00427\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00427\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00427\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00427\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00427\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983: 0s - loss: 0.0050 - accura\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00427\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00427\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00427\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00427\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00427\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00427\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00427\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00427\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00427\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00427\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00427\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00427\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00427\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00427\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00427\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00427\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00427\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00427\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00427\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00427\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00427\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00427\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00427\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00427\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00427\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00427\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00427\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00427\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00427\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00427\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00427\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00427\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00427\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00427\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00427\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00427\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00427\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00427\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00427\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00427\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00427\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00427\n",
      "Iteration is 19\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00427\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00427\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00427\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00427\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00427\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00427\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00427\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00427\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00427\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00427\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00427\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00427\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00427\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00427\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00427\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00427\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984: 0s - loss: 0.0045 - accuracy\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00427\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00427\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00427\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00427\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00427\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00427\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00427\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00427\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00427\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00427\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00427\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00427\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00427\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00427\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00427\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00427\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss improved from 0.00427 to 0.00427, saving model to unet_particle.hdf5\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss improved from 0.00427 to 0.00425, saving model to unet_particle.hdf5\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00425\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00425\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00037: loss improved from 0.00425 to 0.00422, saving model to unet_particle.hdf5\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985: 0s - loss: 0.0041 - ac\n",
      "\n",
      "Epoch 00038: loss improved from 0.00422 to 0.00418, saving model to unet_particle.hdf5\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00418\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00418\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00418\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: loss improved from 0.00418 to 0.00416, saving model to unet_particle.hdf5\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss improved from 0.00416 to 0.00412, saving model to unet_particle.hdf5\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00412\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss improved from 0.00412 to 0.00410, saving model to unet_particle.hdf5\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00410\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00410\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00410\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00049: loss improved from 0.00410 to 0.00407, saving model to unet_particle.hdf5\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00407\n",
      "Iteration is 20\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00407\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00407\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00407\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00407\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00407\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00407\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00407\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00407\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00407\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00407\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00407\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00407\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00407\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00407\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00407\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00407\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00407\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983: 0s - loss: 0.004\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00407\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00407\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00407\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00407\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00407\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00407\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00407\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00407\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00407\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00407\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00407\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00407\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00407\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00407\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00407\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00407\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00407\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00407\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00407\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00407\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00407\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00407\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00407\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00407\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00407\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00407\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00407\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00407\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00407\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00407\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00407\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00407\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00407\n",
      "Iteration is 21\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0052 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00407\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00407\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983: 1s - loss: 0\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00407\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00407\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00407\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00407\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00407\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00407\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00407\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00407\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00407\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00407\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00407\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00407\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00407\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00407\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00407\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00407\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00407\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00407\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00407\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00407\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00407\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00407\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00407\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00407\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00407\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00407\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00407\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00407\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00407\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00407\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984: 0s - loss: 0.0045 - accuracy: 0.99\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00407\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00407\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00407\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00407\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00407\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00407\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00407\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00407\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00407\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00407\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00407\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00407\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00407\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00407\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00407\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00407\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00407\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00407\n",
      "Iteration is 22\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00407\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00407\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00407\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00407\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00407\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00407\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00407\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00407\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00407\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984: 0s - loss: 0.004\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00407\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00407\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00407\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00407\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00407\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00407\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00407\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00407\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00407\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00407\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00407\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00407\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00407\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00407\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00407\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00407\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00407\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00407\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00407\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00407\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00407\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984: 0s - loss: 0.0042 - ac\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00407\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00407\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00407\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00407\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00407\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00407\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00407\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00407\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00407\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00407\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00407\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985: 0s - loss: 0.0043 - accu\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00407\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00407\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00407\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00407\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00407\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00407\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00407\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00407\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00407\n",
      "Iteration is 23\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00407\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00407\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00407\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00407\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00407\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00407\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00407\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00407\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00407\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00407\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00407\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00407\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983: 0s - loss: 0.0046 - accuracy: \n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00407\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00407\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00407\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00407\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00407\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00407\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00407\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00407\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00407\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00407\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984: 1s - los\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00407\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00407\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00407\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00407\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00407\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00407\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00407\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00407\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00407\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00407\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00407\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00407\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00407\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00407\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00407\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00407\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00407\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00407\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00407\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00407\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00407\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00407\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00407\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00407\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00407\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00407\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00407\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00407\n",
      "Iteration is 24\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00407\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00407\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00407\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00407\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00407\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00407\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00407\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00407\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00407\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00407\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00407\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00407\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00407\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983: 1s - los\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00407\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00407\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00407\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00407\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00407\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00407\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00407\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00407\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00407\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00407\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00407\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00407\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00407\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00407\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984: 0s - loss: 0.004\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00407\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00407\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00407\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00407\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00407\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00407\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00407\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00407\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00407\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00407\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00407\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00407\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00407\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00407\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00407\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00407\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00407\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00407\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00407\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00407\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00407\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00407\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00407\n",
      "Iteration is 25\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0053 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00407\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00407\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00407\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00407\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00407\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00407\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00407\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00407\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00407\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00407\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00407\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00407\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00407\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00407\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00407\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00407\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00407\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00407\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00407\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00407\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00407\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00407\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00407\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00407\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00407\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00407\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00407\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00407\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00407\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00407\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00407\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00407\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00407\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00407\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984: 1s - loss: 0\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00407\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00407\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00407\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984: 1s - loss:\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00407\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00407\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00407\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00407\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00407\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00407\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00407\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00407\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00407\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00407\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00407\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00407\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00407\n",
      "Iteration is 26\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0050 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00407\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00407\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00407\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00407\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00407\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00407\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00407\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00407\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00407\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985: 0s - loss: 0.0048 - ac\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00407\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00407\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00407\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00407\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00407\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00407\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00407\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00407\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00407\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00407\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00407\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00407\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00407\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00407\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00407\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00407\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00407\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00407\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00407\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00407\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00407\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00407\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00407\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00407\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00407\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00407\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00407\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00407\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00407\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00407\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00407\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00407\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00407\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00407\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00044: loss improved from 0.00407 to 0.00406, saving model to unet_particle.hdf5\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00406\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00406\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00406\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00048: loss improved from 0.00406 to 0.00401, saving model to unet_particle.hdf5\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00049: loss improved from 0.00401 to 0.00400, saving model to unet_particle.hdf5\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00400\n",
      "Iteration is 27\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0051 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00400\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00400\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00400\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00400\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00400\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00400\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00400\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00400\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00400\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00400\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00400\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00400\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00400\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00400\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00400\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00400\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00400\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00400\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00400\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00400\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00400\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00400\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985: 0s - loss: 0.0044 - ac\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00400\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00400\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00400\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00400\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00400\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00400\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00400\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00400\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00400\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00400\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00400\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00400\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00400\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00400\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00400\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00400\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00400\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00400\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00400\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00400\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00400\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00400\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00400\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00400\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00400\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00400\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00400\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00400\n",
      "Iteration is 28\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0053 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00400\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00400\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00400\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00400\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00400\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00400\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00400\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00400\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00400\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984: 0s - loss: 0.0048 - accuracy: \n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00400\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00400\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00400\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00400\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00400\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00400\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00400\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00400\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00400\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00400\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00400\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00400\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00400\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00400\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00400\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00400\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00400\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00400\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00400\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00400\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00400\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00400\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00400\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00400\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00400\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00400\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00400\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00400\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00400\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00400\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00400\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00400\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00400\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00400\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00400\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00400\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00400\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00400\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00400\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00400\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985: 0s - loss: 0.0042 - accuracy\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00400\n",
      "Iteration is 29\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00400\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00400\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00400\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00400\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00400\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00400\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00400\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00400\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00400\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00400\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00400\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00400\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00400\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00400\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00400\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00400\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985: 1s - loss: 0.0\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00400\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00400\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00400\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00400\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00400\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00400\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00400\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00400\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985: 0s - loss: 0.0042 - accuracy: \n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00400\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00400\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00400\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00400\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00400\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00400\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00400\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00400\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00400\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00400\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00400\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00400\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00400\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00400\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00039: loss improved from 0.00400 to 0.00398, saving model to unet_particle.hdf5\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00398\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00398\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986: 0s - loss: 0.0040 - accuracy: \n",
      "\n",
      "Epoch 00042: loss improved from 0.00398 to 0.00397, saving model to unet_particle.hdf5\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00043: loss improved from 0.00397 to 0.00393, saving model to unet_particle.hdf5\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00044: loss improved from 0.00393 to 0.00393, saving model to unet_particle.hdf5\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00045: loss improved from 0.00393 to 0.00392, saving model to unet_particle.hdf5\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00046: loss improved from 0.00392 to 0.00389, saving model to unet_particle.hdf5\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00389\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00048: loss improved from 0.00389 to 0.00389, saving model to unet_particle.hdf5\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00049: loss improved from 0.00389 to 0.00388, saving model to unet_particle.hdf5\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00050: loss improved from 0.00388 to 0.00386, saving model to unet_particle.hdf5\n",
      "Iteration is 30\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985: 0s - loss: 0.0043 - accuracy: 0.99\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 31\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985: 0s - loss: 0.0044 - accuracy: \n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985: 0s - loss: 0.0044 - accuracy: 0.\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985: 0s - loss: 0.0043 - accuracy: 0.\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985: 1s - los\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985: 0s - loss: 0.0041 - ac\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 32\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984: 1s - loss:\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 33\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985: 0s - loss: 0.0042 - accuracy\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 34\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984: 0s - loss: 0.0045 - accura\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984: 1s - loss:\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985: 1s - loss: 0\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 35\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985: 0s - loss: 0.0041 \n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 36\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985: 0s - loss: 0.0041 - accura\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 37\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984: 0s - loss: 0.004\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984: 0s - loss: 0.004\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985: 1s - loss: 0.0\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985: 0s - loss: 0.0042 - ac\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 38\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985: 1s - loss: 0.0\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985: 0s - loss: 0.004\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 39\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984: 0s - loss: 0.0047 - accu\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985: 1s - loss: 0\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 40\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984: 0s - loss: 0.0047 - accuracy: 0.99\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 41\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985: 0s - loss: 0.0043 - accuracy:  - ETA: 0s - loss: 0.0044 - accuracy: 0.\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985: 0s - loss: 0.0043 - \n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 42\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0051 - accuracy: 0.9983: 0s - loss: 0.0051 - accura\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984: 0s - loss: 0.0049 - \n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985: 0s - loss: 0.0043 - accuracy: 0.99\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 43\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984: 0s - loss: 0.0046 - \n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985: 0s - loss: 0.0041 - accura\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 44\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0056 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0053 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983: 0s - loss: 0.0051 - accuracy: 0.99\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983: 1s - loss: 0.0\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 45\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984: 0s - loss: 0.0046 - accuracy: 0.\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 46\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9983: 0s - loss: 0.0045 - ac\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984: 1s - los\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 47\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 48\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0050 - accuracy: 0.9983\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984: 1s - loss:\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984: 0s - loss: 0.0050 \n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984: 0s - loss: 0.0045 - accuracy: 0.\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984: 1s - loss: 0\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.99 - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985: 1s - los\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9985: 0s - loss: 0.0041 - accu\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986: 1s - loss: 0.0040 -  - ETA: 0s - loss: 0.0040 - accuracy: \n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00386\n",
      "Iteration is 49\n",
      "Am here\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.00386\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.00386\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.00386\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.00386\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.00386\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9984\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00386\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.00386\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.00386\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.00386\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00386\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.00386\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00386\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00386\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.00386\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00386\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985: 0s - loss: 0.0044 - accuracy: \n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00386\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00386\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.00386\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00386\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00386\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.00386\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.00386\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.00386\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985: 0s - loss: 0.0041 \n",
      "\n",
      "Epoch 00024: loss did not improve from 0.00386\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.00386\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.00386\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.00386\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.00386\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.00386\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.00386\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985: 0s - loss: 0.0041 - accuracy\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.00386\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.00386\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.00386\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0041 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.00386\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9985\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.00386\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.00386\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.00386\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.00386\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.00386\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.00386\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00386\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00386\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00386\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.00386\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.00386\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00386\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00386\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.00386\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00386\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00050: loss improved from 0.00386 to 0.00386, saving model to unet_particle.hdf5\n",
      "Iteration is 50\n",
      "Am here\n"
     ]
    }
   ],
   "source": [
    "image_parameters_function = lambda : imageGeneration.get_image_parameters_optimized()\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "### Define image generator\n",
    "        \n",
    "imggen = imageGeneration.batch_generator(image_parameters_function, 500)\n",
    "        \n",
    "model_checkpoint = ModelCheckpoint('unet_particle.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "\n",
    "iteration = 0\n",
    "for image_batch, target_batch in imggen:\n",
    "    if(iteration>=50):\n",
    "        break\n",
    "    iteration+=1\n",
    "\n",
    "    model.fit(image_batch, target_batch, epochs = 50, callbacks = [model_checkpoint])\n",
    "    print(\"Iteration is \" + str(iteration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests the network on the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 312, 512)\n",
      "(1000, 320, 512, 1)\n",
      "(1000, 320, 512, 1)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.2) C:\\projects\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:668: error: (-215:Assertion failed) image.channels() == 1 || image.channels() == 3 || image.channels() == 4 in function 'cv::imwrite_'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-47c1a0fb2eb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data\\particles\\movie\\label\\label\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelimage\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data\\particles\\movie\\frame\\frame\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.2) C:\\projects\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:668: error: (-215:Assertion failed) image.channels() == 1 || image.channels() == 3 || image.channels() == 4 in function 'cv::imwrite_'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "im = io.imread('bild.tif')/255\n",
    "print(im.shape)\n",
    "\n",
    "\n",
    "batch = np.zeros(im.shape+(1,))\n",
    "batch[:,:,:,0] = im\n",
    "batch = np.pad(batch, ((0,0),(4,4),(0,0),(0,0)))\n",
    "print(batch.shape)\n",
    "model = unet.create_unet()\n",
    "model.load_weights(\"unet_particle.hdf5\")\n",
    "A = model.predict(batch)\n",
    "print(A.shape)\n",
    "#Shows the first 10 images\n",
    "for j in range(2):\n",
    "    labelimage = A[j, :, :, 0]\n",
    "    image = im[j]\n",
    "    cv2.imwrite(\"data\\particles\\movie\\label\\label\" + str(j) + '.png', labelimage*255)\n",
    "    cv2.imwrite(\"data\\particles\\movie\\frame\\frame\" + str(j) + \".png\", im*255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests the network on the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-9f20ff58264b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/particles/movie/frame/frame\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabelimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/particles/movie/label/label\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\david tonderski\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 723\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    724\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david tonderski\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mdraw_idle\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1912\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1914\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw_cursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david tonderski\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m             \u001b[1;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;31m# don't forget to call the superclass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david tonderski\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david tonderski\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1707\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1708\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[1;32m-> 1709\u001b[1;33m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[0;32m   1710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1711\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'figure'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david tonderski\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david tonderski\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david tonderski\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, inframe)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2647\u001b[1;33m         \u001b[0mmimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2649\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'axes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david tonderski\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david tonderski\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david tonderski\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m             im, l, b, trans = self.make_image(\n\u001b[1;32m--> 619\u001b[1;33m                 renderer, renderer.get_image_magnification())\n\u001b[0m\u001b[0;32m    620\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david tonderski\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mmake_image\u001b[1;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[0;32m    879\u001b[0m         return self._make_image(\n\u001b[0;32m    880\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_bbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagnification\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 881\u001b[1;33m             unsampled=unsampled)\n\u001b[0m\u001b[0;32m    882\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_unsampled_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david tonderski\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_make_image\u001b[1;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[0;32m    354\u001b[0m                 \u001b[0minp_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m                 \u001b[0ma_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m                 \u001b[0ma_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m                 \u001b[1;31m# figure out the type we should scale to.  For floats,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m                 \u001b[1;31m# leave as is.  For integers cast to an appropriate-sized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david tonderski\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\ma\\core.py\u001b[0m in \u001b[0;36mmax\u001b[1;34m(self, axis, out, fill_value, keepdims)\u001b[0m\n\u001b[0;32m   5805\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5806\u001b[0m             result = self.filled(fill_value).max(\n\u001b[1;32m-> 5807\u001b[1;33m                 axis=axis, out=out, **kwargs).view(type(self))\n\u001b[0m\u001b[0;32m   5808\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5809\u001b[0m                 \u001b[1;31m# Set the mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david tonderski\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     28\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[0;32m     29\u001b[0m           initial=_NoValue, where=True):\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "#Shows the first 10 images\n",
    "for j in range(1000):\n",
    "    labelimage = A[j, :, :, 0]\n",
    "    image = im[j]\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.savefig(\"data/particles/movie/frame/frame\" + str(j) + \".png\")\n",
    "    plt.imshow(labelimage, cmap='gray')\n",
    "    plt.savefig(\"data/particles/movie/label/label\" + str(j) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO29b4ymy10deGpNLmvDZcExMzG3x7kmcpJluXcT7hUbbTYIyRswrNdOlM3K7E1kLUbWSoQ/PYvAN3xYvqDAou1WviSRA1acrBNCCAgrmggSZwlZaSHMODZjcJzYYOg2d2eCCSKbWLkxqf3Qb7VPnz6nqt6eO9Ov1XWk0bz9PPXUv6eeqt+f86sqtVYsLCxcXfwnl12BhYWFy8WaBBYWrjjWJLCwcMWxJoGFhSuONQksLFxxrElgYeGK46FNAqWUN5RSPlJK+Wgp5R0Pq5yFhYUHQ3kYPIFSyssA/AsAfxzAMYCfB/ANtdZfeskLW1hYeCA8LEngKwF8tNb6y7XWFwH8MIA3P6SyFhYWHgCf85DyfQLAEf19DOC/Solf9apX1SeffBJ37tzBtWvXAAD3798/83uEa9eunabj38888wzu3Llz+vvo6GiY5zPPPAMAePHFF0+v3bt370waV9ZTTz11ev/u3bunv9v1lEfLp11rv1M5vd8ub+6Dp556Co899thp+7ienL71EwBcv379tE1chtZX29Oe4/545plnTvuV+2Om3dy/9+7dO/OOub7u3XN97t27hxs3bgAAjo6Ouv3XxkJLq/fbcy2/O3funKsncNKHrQ/4HfCY53w5zdHR0WndH3vssTP1YLQ6vPjii6fl3rhx47S/7969+xu11i/W5x6WOvCnAXxtrfWbNn//WQBfWWv9FkrzdgBvB4DXvOY1z/zqr/4qSinY398HABweHp75PcL+/v5pOv5da0Up5fT3zZs3h3m2Pjk+Pj69dnBwcCaNK4tfTnshfD3l0fJp19rvVE7vt8ub++Do6Ah7e3un7eN6cvrWTwBOf9+4ceNMGVpfbQ/n0cqptZ72K/fHTLu5fw8ODs68Yy7LvXuuz8HBwWnZN2/e7PYffx+ujPZcy6+Ucq6e7VmeeNo74DHP+XKamzdvnpa9t7d3ph6MVtbx8fHp74ODg9P+vnHjxp1a67P63MOSBI4B8OjaA/DrnKDW+k4A7wSAp59+uh4fH595UYeHh/YjUbQ0nJY7iT9k7bz2gvV66mRGe9H6EbXOPzo6Or2ng72htenmzZs2zdHRUUzP7U4ff6tj+xBcXdzkw/kfHR2deYY/JK5Tr00HBwenfc0fSZqouO488Whfj+qbPlr97cri+rqxx++3pWt14utcd7cYcD77+/tn6tJ+37x5M04aDLfYpYme8bAmgZ8H8LpSymsBfALAWwD8Tynx3bt3T1+A60CZzU7v6wtvL1cHzqjT9IUy0seeJqi0Iuhz/Ex7we26fmitfVwGSytO6kj9lOqgaVo+e3t7VmpKKynXnZ/jvHlF5P7iCYk/jDQpuwlPxw+/g9bPvcVFFxWdYLlf+KOekfbavdQvCpYEnITAkyZ/+NyXvfwbHsokUGv9dCnlzwH4SQAvA/CuWusvPoyyFhYWHgwPSxJArfUWgFvbPKOiLa8SDXyfZ321bSTxr0F1LqfH6YrBqwPXzakkDkkq0dXUla8rO/cJX+d0vOI6cH9z3VI7Uj68CrM6x+I6r+ashqW+Vsmnped3ltrN5SYJz70/t8omaYzblFRRLZ/tDE2yVSmH1SxWZZ3qymNJ+5fVgdF7fWiTwDa4du0annvuOQBnxTBn1ElibjIqMvg6i6uqhjTwB6kD2X2EPFEAODdg9X4DT2AscvaMo+76wcGBbfeNGzeijusMcHrd6bVOZXH1a8+1v3kC4/eadHlVI1o7tD+4fake3Daug6tng9alfZiHh4dRTWEjntPxdayyKpFUL9b33dhr91r+PGmMFqdFG15YuOJ4KC7CbfH000/XW7dunRNJnbElGXVY9FK3UhI5G3iGPzg4iC4x97waLXvSiBqyRu3SPNzqy/3E95IUweVyWw8PD60FX+GMUpw3g9+HQ3KzJZFapYWRsVMt/27FHUlnvKoy2A3Xe08sFTjvR0un7ZgdH3yt921s+uCRuggvhKR3cyf3PqyRrz2lYQs7v5xeHs7anTgJ2kbgvK45I5Y7vXd/f9/qyenDS16OJGbqx8OqTS/vWuuZD3Dkcmv32rOq87d8Zqze7kPi/pt5r+w5GnEmdAJjbw+PDa4758/vgMt3Kk6anFldvXHjxvC9MpY6sLBwxbETksC9e/fOkGyA86uKs8Tu7+/H2ZJF3jTzOzEwqQDJEstgL4Nb8RKzTMt0faAGKl5JtjGgcpuSwYhXzcShSOW0v9OKn1Z5ZsIpGYqf5bY64yXnmQg6SdXk1TRJHCNpgklunOb4+Dj2O48ZXumbmsn9ylIVI6kb7GFIWJLAwsIVx5oEFhauOHZCHbh+/fqptdeJWyxaqog58vcqYcMZBpWW2cCqhIpwzjCl/lxVG5IRSvnjTvxmi7byHRz5JpGqGMky3rOq92IHVIVjn3qDqgnOo5OCdvTZpLY5b4K2e4ZE5PJwKpwaip2XY29vzxoGuQ9UzHeemKOjIyviHx8fn6lbytNhJyaBBnVr9bj3wFldMLkIb968eSbPxN13A129Ek6nY944D9KkEzvL9UxQT3vGpWddOrmtOA9X7ow1mi3fiYXZwB4XtlUkzwCQA7pmXIQMR25K9gF9rzoRJRdhcj23tnO6Bi7HeaF0MXIksx6z03nB2E6VJr6lDiwsXHHsBFno+vXr1dGG+ffI6t1bQRsSfyCJxT2PQKIZqzVbn03EFJY+nMiZCD+JIMJQItBF+8BZ1VWaSNJKktgaeGVPtGFtB/eHC7VN0kLqM0ewSqQylTK4zIa9vb1h+h5t2KkPD0gbtmShnZgESimnldBO39yHu68f3OhjY6RNG7jc9IIcqSSVweiFNSfGW8rXTUK969uwE9Nk6cJylaSSPgzuU2fD0MlpJoCI67VtANHMZMLpgPObzDjikE5madMWZqi6d899cHBwYCfIBK6b9L2dBJY6sLBwxbFThsEejzttKuJWhpYXkFWDRHJJSIQQLkt3gFGoF6BBRVYn0ajXwm0qkgxhCWp0ZIs/c97ZKOXydG3Sd8mSQKLkcpudKpgMgdpuVZ0a+N2w0c2pmg36LlgybGNS65hIQWw0bqi1nknHdVFVq7UnbSrS6sNSVdoUhrETk8BTTz2FW7dunbG088tMsQMp9JIHdPrwgLM6exLTnSusPaP1ZNG4V662icVM/gCYV67Mtpk9Ftw19qhwHVRVYYu8s0u4OIV0Xz/exApN24s1pI9K68sLg1MTGOxd4TROTWE1UG0b6V1z37gJr8fo4z0HUn0aeBHkCWExBhcWFobYCUngscces2KL8+8nsPjJEoKSOEYbgwBzuw07TgLgOfUsKjqDm6osibeerPeOQ394+Jl9+niVVeNa2vmG282eC1enZMzk3W24LixGN8yQiFQlSvXl606taOlcWVwfzZufV4krhWE7iTR5MzjfZLhO0alcB91teMQT2IlJ4M6dO6edN9IvuYNVhHVuF34pajdIIapuf4CWr9aN80kuHn3e1dc9oy+byxl5GXQQNSTXHd/TnW8ckieGPwbnQVEXnssDgE2TvCsqLo9csyya68KgH0ryWrDbrmeDcAsAl6lj3rn2dAJJniTnpemFbjcsdWBh4YpjJyQBhltV2YqsVv0G3ceOkWIHGtSy6izgvNocHx/b+qgomvYhdHDWZa0ng/vGreBJStK6uA0z+HeKR0j0ZI7lcGI/q3a8mupqy1KMowqncpPHQT0hvXiKlr9rsyN1cX8kQ2SSuhj63p2nhzcsUamu3VPJYeT5uvAkUEq5AeCvA/g9AP4jgHfWWv9iKeWVAP42gCcBfBzA/1hr/de9vJp3IDHkUsemXXL4d89Knwg0Th9NZBrOX5lxmvcMK2/mHtebRc6Uf3KTalsTYcoNXhccpP3pPiT92F3MBjPtVHQf9WVaJLiu6V06NmOP0ORE9B5mCGYpNoLLYlGf2+rc6DM2gQdRBz4N4H+ttf7nAP4IgG8upXwZgHcAeF+t9XUA3rf5e2FhYUdxYUmg1voCgBc2v/9NKeXDODmI9M0AvnqT7N0AfhrAd/Xyat6BRF5RMaxB/bbOCMPiEz8/Es20LIWjjKb8U/QaY4as5MgmybPQo8y6Fakn6jojmlNHePcc9UiMJAs10HE/8iqYLONOWkj8CEXy0rQ8XCQgW+m1n50BUCUthhsficzmwpr1Ot9T8pTDSxI7UEp5EsDPAPhyAL9Wa/1Cuveva61f1HueA4gaVGd3uuPhoQ8oSWJ/z+qt9oVWLrXjzAfmXDzKKGtIHPPkBuNBr23Q/kkxE2qldttyuTa3PF1/6ofq2ufyVDemQ/KQ9BYANzmpypDScN2dCO48BqlP2ROjx8I5T4WqXWkycQFB7LbmBU6vh4CjhxM7UEr5fAB/F8C311p/e4vn3l5KuV1Kuf2pT33qQauxsLBwQTyQd6CU8rtwMgG8p9b6Y5vL90opr661vlBKeTWA++5ZPpX4+vXrFcg0z+RbbvdaWhbrnMGpR+lsuHHjhpUuOJ1GHTKcauGs6ymcVNULFpe5rc4PnKIhAb8iJXWBadQ9w5jmkyQIrpf2L3M4Rtx9NQayipHakURs9qIknkfLg/uu1SepUirtsbTAIr3zvrR0mobL61n7ncGQ32XqpwurA+WkpHcD+M1a67fT9R8A8Mla6/eVUt4B4JW11u/s5dXUAf14Z6ypDSwWOytvu96gL5xdMOkD53x44Cddtof0QtKHpBZtpyokdUTLSwPN6e1JbWLxd2RT6THknGrCdUm2gl7oeCJhOc9Cz43XyzuNsdSnPaIa551sTa4+M3WX+r/kh4/8UQB/FsDdUsoHNtf+PIDvA/AjpZS3Afg1AH/6AcpYWFh4yHgQ78D/DSAt0a/fJi8OmxzRhpOxTvNjY5aKbsDcaqqztFM3VGrorSQqzrpw4CS+sSdE69vAlvpk5Do8PLT5aDtG+Se4/NRYx3VhL45T7bgOPUr1SPJq9W/1ceqOM8qqZMjj1ElpbKBjdYBVuIODg2g8nFGtRlRulXKTetuwE4zB5vrRwerEJ93EkYk6DSxWpQ8g7UaT2FZal7RjjLMCJ1E8veTRh8Z5qp3BvXB1n7qddLUv0i7OvTb3bCWJaMXuRTf5sQdIQ65d/q2Nmk4nP2ffcSK4vk/nGlV3NsOptz11k8cB90eyOTBSfMFIvV2xAwsLVxw7IQm0cweAMcXW+d8b3MzJszfPirzCqIiViEYNalFuUBpnu+f21NP68srEGPUBt+Pw8NDy9dlYxStuMkrpasbXeW88bTPXN62o6olxVnqVnBIHJBFiuCxOnzbY6G1cwvkpb5/f2Yib4NQbV19tm6InvfEzPfq6YicmgYbRyxhBBxhwdmccxv7+/jnVQuvAIhnnz/p5Yuy5/QS0ji2t1i9ZsVOsQ8ufB0gi3/C+DcmjonVxIjCD82fRvT2nqk+D5sfi9Wj34N7Jxc4lywQvfmdsH3D11PYndyynZ7hJP9lrlIXoJkWe9LUcZ1NJ75Wx1IGFhSuOndpyXFddR6BJvt8ULZhWRKUcJ7KOW5XTri8jqA/Z5cFi5ow1PrVRRfdknXdEmd57cP58lixUXWjtc8ZWlm6Yb5DeWe/eiATFddP69bgdLDWwNKH1deMzUcC5/B6FmeHGWE81duPmMGw5vlPqgIrWTqxT8KDXvBrSdk8sRs8E8HAeSXfkl+gmpVFYs7ouXd6JB6/1dNe4j9N5gSpa8nvQwcvPJZsI962GuTovRLJPpEGvadykleJGaq32w3NqUvrYkwVe253GaoO+u6QKpvQpz5H7dKkDCwtXHDulDgBnDTxp80aGI1ckDgBwlsySRKwROYUJJCou9iSKtO9fj1gzqksirbh8FbqSOG+Jrsq91Uf7OW0hnqi3M2W6cdCjPyc1z9UzqTMOWp7zlvQ2tElqYVJNZtTeUVt3Wh3gnYUaeCDs7/t93fUDdA3XQePE3N7H66zw/AITWScxu9zH3ys7eS0c9OMZbaumfcmqwUg/Hqlbmn9SjRyLL3kTGGqfcKrC4eGh7TfeuYj7Uk9SbvddPyZPDWMmDbMKAX/sGefT8zqlAKzeSdLAUgcWFq48dkISuHfv3jkjklpzHdQg445nSiKsGtecR6BnLGtgg51eZ6s5cJ5XnlQWBluXnaEt+dpnfNEsafBKkoyWicDlwCrcwcHZY9N6m2Xy/1qmGsjcs9ofjj/AUhIbiJ0XKhkAnafEIR18yu8yRXXqe2sYnZehz468VzsxCTDcx6CDnq/zy+c83GBVEkUSjZ1Ir6JXenHtQ9/b27Px3Q2JGZgmEh7Y/CHrh+AYeFpHzqfVl3VNZTbywNdB3SM6OftLUil4ACcCVs+GkCzvjlykqqNzX3LZiRWa1DiuSyuTbVYaR5BsGA3pg9byHVNxZMcBljqwsHDlsROSwP37909nf8exThsttntAtpKnlQfw3P2jo6NoIXbxAokH7sKcuX0sEquI7qQSlSbS6uQko6QaJN+5tptXHPbA6L1EEEqSCK+yetCm8xQkWnki6KhU5VZHVgWdL5/PmFCDsFNFuY84nx6HP+XDefB7dVJgeq8z2AkXYdtZqGeldx9DOuAD8B8sQ0Xe5JbrWdPbtZ5OyXVJ+xPoRpWJOec+mCQeahxBGhRJVBzFoDtVQ8t3MfPpWK/0rOr4TvdPrlHdC4BtNGnS1fok+4iyD51qoxuEsk3C8fz1HTf0VC6+ljw6hIez0ejCwsJnN3ZCHWihxD0/uzslVlcp52dOvuTeHm68mruZXA01aTckt8qleIV2PZGF0urR6tny5lUwrZoM3kHH9VmSdJyVXkVk7o+0IUjyPCRy0cjSzaodI6kGKhFqelVl3IYsKm3we+L0qX2OG5CM27McEdeWJPXtxCTALsK0yWZDrxOSa2/EwEv6Jb9ERXI7uqOgGEn/Gx3rpe1O/HiXZm9vLzIGXci1qi2tnm6gKWGL655UFefK0v50TFBl9424/urx4LqNxPGG5OpMnqOWj/5O9hJlujqylcYvuHJ08ptxXzYsdWBh4YpjJySB5h1Ilt0eScXNusnfCuRTdxwSlyBJDsnC7cpkKy/Tonk1mLHy8kqtdWdjI19PBCQuK/mrk8EMOG8gc+rQ/v6+lZZ05XLShZ5T4CSN/f19KyUlz0LiWSR1IamZI6+WjgEX3ZgMjDdv3rTqg5KJnEQxQ8FeksDCwhXHA0sCpZSXAbgN4BO11jeWCxxNfu3aNTz33HNxVgbGATB6jw1OLlBof38/uq0aVFJIbkGepd3qx+Wz3s0zutMd1dDmwLogtyGxxhK7TnkFfNa9i3wcIW2Ioiur6w91AzuJCjhrU3GcD22jG0MsJWn/NaT+ZYnNrc5cP5a0eEz2dip29g/msTCOj4/P2C6cNPkwDYPfBuDDAL5g83c7mrydQPQODE4ldhuNJsySIJxFF/BiLuBDjPlD6tUr+bQVifSRjFlc7siToXXUj3pEMOG2cpSdegHcJMflu4+B68leC1U/WD1q4AGvlvTkLdEyR9d7fcwqoaoLbMlnw67j3uh7Td4P9/GOdkRyGHkZGA+kDpRS9gD8dwB+kC6/GSfHk2Hz/594kDIWFhYeLh6IMVhK+VEAfwHA4wC+Y6MO/NaDHE0+mrVmoqmAvEI6OjGjZ1RMK0sSu3lldfUdGS97UgXXdyTuKU/AiY0poInrw1yChp4kMsN8TEjq34ipmeq+La3cGZn5/WqUa9ovsoHdx4yUp0qNKXCK25wM43T9pd1UpJTyRgD3a613SilffYHn3w7g7QDw+OOPn14fvTTlETgOQE8sn6EEOz2Sr6vOOoqQc4QY9b8zHTXRYR3NGMCwfP6brcjqa+f8+ANzOmvyeHCb3fu4efPmuXfIbdByOF+dLF3/9SaWxDcZ2TqcR4RDolll4PfKthUlFHG7Z/gGI/sRgyeTGfX5QQ8kfVMp5esB/KcAvqCU8n/iAY4mX1hYePR4kANJnwfwPABsJIHvqLX+mc3R5G/FyenEbwXwE6O82mrDhhEVgdKK1aBiW4POlmzkGQX2cHqFk0w4Pc/Abvsojk5jizbTS5OIy21PUgtDjU8NSuV1jEGWFthYNWPkcuUfHJzdDThRqx2HQpGMtiwNuWc5z94+Bu2+MyzrFmXO4JoMtYeH+WxBZ/hLdOkkwXD6pPYyXpIoQpoE3lhK+d0AfgTAa7A5mrzW+puD5+1Go4zUEPeR9jYaTXpfippL4nWKcXD6I98bqSmuLZqfo+9qPkndSfqiekJm7RJKbnGElTQQk/clxXtwvRj8QaqrkctNno2eSqJ94TxHPc8Kq3m8qI2ut3uurNHCxJMJqySllIe30Wit9acB/PTm9yex5dHkCwsLl4edoA036EzISKKPmxUPDg7OrHw937bLf2RtBzz3gGf+Gcs+15frwcakZL131mKuu7ZDIyjb/ZavqieMJOm0v1OQjquT+sIZSULhejgJTwNymFjD/ccGWtc2Jn45w672i7t+cHBg+5cNeupBcLwIHRM8rpKBmtMnSdFhJzYVaerAzAYSiuQmctcTjzoN0uSeUlGX9XxnSU4i+iiOoce6S7vnjOIh+BkVrx1hqad69OqiUYTJ3eWYlwDOxD0kxmLyDCV7Bbd/pH44UZ/rqCqIy1ttWaONShJRTd2Io41G0yGuyUW4YgcWFq44dkIdaLEDiRvQ2wAkkSiSuNyQpA5dwfR+S+Miy1p5mj6J6GnVTrHgib6akPZEdP3E+wn0jJfaPhZz1Q/vvBxJVWNVULkE3B5nbNR3w6u/U0uchAKcpTQzHB9BpSj3jlt9ND2TrlTSGkX86WY0DUdHR/bZniGxYScmgfayeFAk9pnCDXQegIlrraJdA4v0wGdeqIrd6bSe3kfZY7+5F5XCe7nO3FadPJKHxOWp4ifXmT9ULUu9Fq5s7QPu02SFTyfxuLKSWsWkKp78gOwJ0PvJa5Im8d6H7MhW+pGmswMYPCnpNYfRfpFLHVhYuOLYCUmgIYlXiYSilti0OnCeIzJP8mnzdeXQO/Ga67ANscaV68DPjCLSNJ9U36Q2MbgPWjnO+6J96Pq0R91NKpbzCCQJS6UObqdb6Uf15FW+t72Zq4tTEdpvrn9SExqS2J/Ib4loxNgJ70AKIHKDW5GswiPrvN6f4VgztiGeuEkgid9cX303IxZYj6ueQnyTCqDtcWW550ZkL60jvz93vd1rSHz90USkXhwHt9mqegc47zSWnJVe1QrnsUpBV1oGl5Xuh8VjeQcWFhbOYyckgcYTSLNZ73BSDtMdzZZJWlBSjos96BngOE1PJGZw2uQNSBKQqkSJpMPXk4TAdU0iMuehYq/SdN3+fknSaeVqfZUz4NqkeSYuvmu3km961GU1RibqdpKMtm1f4sa4PtP3PtGvVhLYqUkAyJbMmYZzHkmnTJbk9LE5C7Dqg67zZ0Rq93yvvg2p3Yk4lLwPCUnUdRPDTIwGv4+eGpYms9RWV0fOJ6kqvY9Ln9V28ISR4keSKtqeVZuSG5PqieHFLnnEmDXJRCYaT0sdWFhYOI+d8g7s7+/bFRzwhjhdJdvMmTZXZHXg6OjIinzKhU9WXWcZTsawGWNkkhaSupMMTq58V3aqY2uPa1NaTfk51z6te+oP9+xMm1J6lVx4pUzHxWu7kqSyv79/RkV1BlGNIuR8XLyJlufy0XgITpNUjBF2ahLocadnnnW/2R2ku786aECHKyO5qto94Lz9oeWdTptJ3gTnMkofpn5IaZemBm2nG5iaprfzMJfTs1a7j9f1l7ZbbTXOTpTyUVeZq4Ozheg45LHkJl8mQKUAKWU4zjAGk/rA7ZtRzRyWOrCwcMWxE4bBZ599tt6+fTuSGni2VBHIiUbp2d6MmAgpziCjM25SBxRqsHFIHozkg1djVfLTaxkNiYufItJ009Qk0bAFXFW4FE2XrPMJI56Ais5ppeypmsodmIn3mOFc8OrPKkPyFLAay54Nzi/1/cgwuBPqwIsvvnjaAe6D5QGqLzKFBnPHjhhTyitnxlmDvggOdR0FqbTnUlxCj8wzQtJ7e/aHGbG7/VbLtFMP+DnViVsePHBndFc36HUST5NyameyM7g0XL7b5JPz0c1b08Lk0vfAagrDLYhOjeE8eljqwMLCFcdOSAJ37949t4L1RLwG5VSn8N42kycrsq6CjhzCSIa2lMZJMQo3uzP29314NFu0eYVh6UK58o4kxfVjFVGlHK1fInFxHXUlcypIWjWVMJVWeicKKylI89Y0nE9Lw5KOa6PWnaW9RAJTrwJLDqMtypO0zO3ocSgcdsImwIzBRFJxImGyHM+4mBL/Pg1MHYwjZlcSYx0ZKk1CWm/HWFSdcpsdirRuaZchx6BMR2Ml/TZ5elI/8nNJvL4oGao908p3XpEkaicbQ0PS3zmfZFPqMSuTjaKBmZsdtXORhRYWFs7jQY8h+0KcnEP45QAqgG8E8BFseSqxix1Ilu7k/0xWZ13xWdJwqxb7n1Xsn+HFNyQKbKqX3gNwbmONZMkf0WHTvnutLZpGKa5uO+9ElhpJEymaLvVBq49r0wy1mOvI7eMVPbV11C8NSuV1BlZG6kdt8wzJjDFKnySBB50E3g3gn9Raf7CU8hiAVwD48wB+k04l/qJa6+hU4tNQ4m3440BmdM0MEB68Pas+kA+h0ImiR8oZ3W/lJ9WH2+OYjPys1tUN6tYu4LxunwKtdAcb3ghUVQQn5qbYj6Tu8PNJFVRR2PWHTiDOu+NcoIoUYpzUT1evni1kFODG6C00Qb18adWBUsoXAPgqAD8EALXWF2utv4V1KvHCwmcVLiwJlFL+EE7OEvwlAP8lgDsAvg3AJ7Y9lfjpp5+ut27digYTYDuxO4mNPevrNhuY6KqVZu9EitEy1SCVSCIjsksyKvYOHh1FSSZCSkMyZqmxbkRE4meTtJLSc/4pn9477RGyOA/ul97YTNz+BvUg8Lh1KmfiO7i2KKQvX3Ky0I1yrOoAACAASURBVOcA+AoA31Jr/blSyl8E8I7Zh/VU4ua64ob0goVcGudK4g+jp0szR7/Hr2/Pcvmcp3sR7sNgl5/CkUTUVefy0farC6nV15XF9dRgl9kYjkTm4WePjo7OEJH4/ow7a8bLwHmOSFicXt1sWq907qSmH7Epk16v7zIRy3rlt9/OxZpU6gfxDhwDOK61/tzm7x/FyaRwb3MaMUanEtdan621Pvvyl7/8AaqxsLDwIHhQw+A/AfBNtdaPlFK+B8DnbW59kgyDr6y1fmcvn2YYTDPV7KkrDtuITi2/dBQUI3kiuFxdnXrGpJmIvxHttJdmxIlIvxnqOWn5Jt+6M87qBiPcR84o5wygwFmRureJzMiAqsZM985c+3r8E/e+U9ShelPcOEieDSXEuRiSGcPggzIGvwXAezaegV8G8D/jRLr4kVLK27A5lXiUyf3797tkjzQoDg8PhxzsZBXme5xn2otA048+GEYKYR55M9KLPT4+tjo2P9sjIyV2orOdcDp3zBqrQMpYdOC6a9BLu86TA/evWti5fumD6dWjlcv959ytHBfAE1hy/To1jtuhH767ruD2tbqrC3nbuJOGB5oEaq0fAHBuZsE6lXhh4bMGO0EbZnVgtML2rLLJAJes50kUdnvH9cJIGaM6b2OtTtd7XIIRaaZHuHHgujOZJtFnZ9qfuB1uBU91TKJ+2puyRxrjuqSyFOn9JY+LPjujtjlC08wY7JCzdnejUZ4E0kagMxht2KgvrqeCNCSr70xMfENihyW3VtpUckR66hF0OM90ivJoguQ2JPKK65fE/+8xHHkQj/blTxN9YhVyetXVVRXshT2nxWV0OrCrv+Y5s2eEYmQ3wDp3YGFhwWEnJIEWO9AjibjVlFeJWVpvg0oII+JJ7zqjN6v3Vlu+NsPFH21OAvh96XqkqxmxXlf0RJtW3nxanR31Nxm4klqh72IbctFI+kxSH3tKWBKY2TBESUfOeKjcFSd1aNuSukj9sbs7Cz3zzDO4ffs2jo+Pz3y8reH7+34HIW14A7/UdMqr6qajbbl6zC4HfYntOQcdXEntcAQW/WBG+mWPx+/aqm1qaOqF7j3Q8lRVxsUoqPrg6s790ROF+X2kcyLdRJis/Fy+Uwm03/l9jAK6kotSvStpjDm3uLI8edIdTUpLHVhYuOLYCXXAHUg6E+2WTnJJFmhOP2NJZ8xYfZNYOQobTWAxEPAW+Z6omNQdzp/rk1aw3kqopJa092Ki2I582z2/P2+04fLptYnrwGK9Gj5nojr5nkqMLoqQ0yfDtY63UUxBL86E0u+ud4BtAs6KrUy0BiVlsH3A7QkAzLl73Mvexn3Unpv50DXtRVyHnI8LROJ8Z6397jp/MHzNeTZcul59kydkxo3ZYwZymoZtPVAjC//M+En1TV6iBPUUcDnJTUpY3oGFhYXz2AnDYINap5OhiOHopTPRXolfzQY4frbn429gMcytQrPSwUikZxVA6+L2n+uJ3c7YeXBwYOnVzo/O/aXbjzsLOD+rcKsyc/cTbZih4c5OolBrvpM0UznOj59WdqYQs2SmZKH0Ll36HoV+hgjnsLPqgA7a0SDWa2mLsIZZ3X9GF0vsOU2fXISsyvB1ce8M26EvfJvt2ZK+rVupqQisz4yOQOe8dXJyExJf13yd3i4MOTio18W1e8Ym4PLXPhipeclFyJgZtzPpD9dGowsLCw47JQkwdMZzYliPV97Lq6UZ7SaUPAIqms9yvBMfIOXN0LayiDxa1dRTMToKLXkNRrsQJWt8ov7OUGmVb+Gi+7itXLaSm2aiC135rjxN64xyPXWuJ30A/TE8Igu55zdYksDCwsJ57JRhMMVZO/ZdS5Mi/jiNu97Tq9n/PALnc3j4mZN+RlGHHAOvq61b1VIAkbImRzyLnoHKMe1anVp6NZzpyudW4Zlz97QdjlHX7mn9ZgK6lMk3QyfWeqXx6fqhlePycfVU9Pz+DWp3Gdl00njcqUkgkV3a30Dm2XMn6wvi6w2zG4xw+vZ8L6KPd7vR8rUc/u32luP9+NLkwNCJk9Pr0VfaHzwpMbRM175RFKNCJ079rRwHR7iZCcFVGnoaQ46q7t7TtoY7nejTIsX5uHejNPF2z8U5tPTc/yMuxFIHFhauOHZCEnjqqadw69atc6vHjEvMXWfwit/jBnCebhXiVUdXTZfPKG6ey+C68CqoQT2jKD+NTnNiPJBdlq4/U5TgzDZbnJdTDbSfXURhKcUaW3l1TKJ5Mi5vEziVRG41qLs6JgOknifYykzBUcmIqWNwxKFI2IlJ4N69e6cfwogXrS9llF6hL12v6Yvj8pIHIenqmgd/RGznYFE9hQ9PkT5kohrpgjrhuMmM+4MHrOMysC6vXgOOCHUqDtOGtU/cJKOkoIY0qWk+M/wEV/bI/uLUkpa+pUlkth6fguHo9NzfuhgtdWBhYaGLnZAEGtxKA5z3OTNS+sRKc/59XWVHxhw1uqRnedVQMAOQ68v7+DHS6twzjo5i75MPPHEo3MYfzDtQvz/Xi/s6STIz/AEu37Ez1bvjNua4cePGUCrgv1v7euPB9VeSElt9NH3PwDjam5KhEs1DpQ2XUvYBfBNOTiS+i5Mtx1+BC55KnCrcI3fMpHcfpj4zKqtH9tByWt6jMxHcc4nUkoghPf3PtTXFFKjIODPYtPyZPuK81ZvgJjO147iye8esNVyUiJPakFTO5KKcIfborlBph6QZBNfvS34g6RMAvhXAs7XWLwfwMgBvwclRZO+rtb4OwPuwxdFkCwsLjx4Pqg58DoCXl1L+A04kgF8H8DyAr97cfzeAnwbQPZr82rVreO6552KQkCNBAGeJQLqaJn81W6md71VVB/ZRp9U/EVu0zir6Jc+De7Y938sfwJl4/pGxSv9OPvCeRyWtwqnufE2j95yq1jNsOXUrrdwqIjt1SklErb5p92dnEE39zmnUW9N+64qfpBuXf5KY0rthPKg68G0AvhfApwD8VK31uVLKb217KrHbcrznwmtIIlYSqZObLYm0rO/2dq9hjPQ7B53kUiSeGyDJpaX9166rzWEULadc/4ZRZGJSyVI5jPSs1jdZ5917YnuGHmHmjp1zH3UPM8xVNzbSJNrzfKWoxhRfQ3+/5OrAFwF4M4DXAvgSAJ9XSvkzWzz/9lLK7VLK7U996lMXrcbCwsID4kHUgf8WwK/UWv8VAJRSfgzAf43NqcS11hdGpxIDeCdwIgm0627VSUad3irokPYe1HxbmrQvnJ5Jl+DEVSfK6crnLNpqmU79lETRZF12q1BSH9Kej7wyOR8258dU7WRc60UgOqpw4ser9ORWfK4/Gyfd+03vmnkQiQTGUGJT2laNMYp4bfda2t6+FooHmQR+DcAfKaW8AifqwOsB3AbwbwG8FcD3bf7/iVFGfCCp+8jT5gzqZnMvomc9ZyZh8iBwHVpn9sT0kXXcuS7VDZc2A3GiPn94WhfuGwarBs4iz8+onaOV6/qa0894R1KIM79vdXu6dhweHp7ZAj2xEpMa4saL8070PsAGZR0mdzPbB1K9OM2MStKgMSQju8CFJ4Fa68+VUn4UwPsBfBrAP8PJyv752PJU4oWFhcvDTmwq8vTTT9dbt251N/dgkY2vJxUgGQMbZv3+Lk1SKZIxc8Qrnzm1ZoYnoOGnDmwYVGJLQ8/opxboZBhVwg8j9dEoHFhXWccT6El+DTrmdRv7Vh9th7bfxUMkwx23Kxn9dIyN8tex58aZ9M3ubjneJoGk+1+ELNTQY59tQ7jRj8RNVjro085BWuasdbtBbRLJSt7AfXDz5k3r8lLruWtTmgRGrkVlGnL73Bbzvc00Z64nJmTD7GTp6jv6wDlNOiGZ0fOWjEhuMwQk+XbWzkILCwvnsROSAJ9A1JBWmB7cDNlLOzPTJuNkMvo5qSPl7aLp2t+uHU71YTFay0+U4BkuxqhvXJtnVzXXVg2DblALe5IWnMrQkxCcp4CfSeI6r/KjDUu0/clLtM0Ya/da+obkieD0O60OtNgBbfjow0gDitMlko1zobiyEhPMieAuHr3VAcgnJyuH3j07o2vqhJBUA22ntokxM7G47diOj4/P/O1cbun99ew4ow8mvY9Z5iGrJy5dWmiS7chN+skzpPlsG9cxen9pEljqwMLCFcdOhBK3nYUSeuGWPOu7FW+GpppmWvbtJnE5kWn4mRQNxnV3m5om4onWxbUr+dRVbHS8gp5fuWdQ475WSSGpFM7AqBx+xyFJcQfKueA0I4mQ1TKnvvA7Sl6Dvb09y3Hg98ScCJUWHNmq9aHWQb0a21KdG3ZiEuCdhRp0cM5YRPm6S69p3aDQGAG2mLuB0/tgnNjudErOR0Vk19ZkB0jPqorBA9OpIWmPBLWUc3ptR7rf6tzKdO9JCS6uvvqxad6tLuxadrYenYCdCsV2C1cmQ20VM65L5znhumt8wUj3T3mm55Y6sLBwxbETkkBDMsS5ENCW3lnYdSVJxpxRCDDgfdaJmppEXmcQ0hUoGewYbtXWFW6bjS6As9RpB5bCHMml1npmpXaG0WSYnFlN1cDJhj7nKdhGDNb0rp7c5uPj4yghubiK1A4dbyOimKo+Delb0PGfSFsNOzUJAP6j4w9cPy4eIOmFNhwenuXZJ1IKi2ScZ3IPOfBEkeL62aKdDjpJAy0RT0Z2j2RZnnXHantTHyaXWKtnSzMSr/f29s70gQv2SfWf6TO9rh+wTjxJ3eEFqH3kvS3pnNrGE0WvrTNwdV7qwMLCgsVO8QSAORpwwyzNmPNMR307a7D670f8+p6hssFRaXk17Z2sw/mljUlZTG9IlFxG4jhoufp+1Njp3p/67hNHI73PhhlSEOep+Y0MqwxHgNLNSDjEOfEzZvz+PCbc+AB8eHlvsxH3LAJteOfUgQbd1slBmWQjFhh3oA7GkeiaXHGcJg0uZ2nmuvBg6Z1q28B9k2wnSm5iEdUNUu6nHuuuIem97oNSlYoniiSuO1eZuhETOYbhiDsHB2d3o3aTNH/g3A7nRk3t03q4/uXneULld8b17U2gnD+PSTcxM5Y6sLBwxbFT6kBPlJrgRVuRvicyjYx7yao+E57cy4fzavk1KI3UhY2m1VnVkZHXotcf7nf7u5cnY1ux3FnYk7EzhQ8nunTqj4ODszsXaX8rZXpE3eb8ElRUT7wJlXRb+hGSSplowzs1CaSX1tvR1umjmsfMYHQfW29ymBn4PZ4939cdfkb11cHBAzZtezbqJ0aaEPgwD0ayifQmKwc3OSQ7APP8U1y9lpPYeA6O3ZfITdsyLNPEqvm6+my7IEoeK3ZgYWHhPHZCEuAtx5N4P0JSH2Z+9yLuZsgnTnzvrZicP9DfVzCtSAynWvTSuDqxNKTp0wrd0o3qnjAjHWg6BvefUx96XqJRuxM/YxvP0az0w++4QbkoLmxZ4cazqFm7qw6kcwdc2GjSn/lFuMEK5IklDdheGO0MucapAyMXKN/rHa/ldHm1EDtPBKeZcUdyfVLYb0NyMSbxVPMeuQgVo2O6RhNfDyO357bjqucuHBGd2Bukk5yrAxOWZAJZ6sDCwsJ57BRPYH9//8zq5YxcSTznGTvNruyHTaoHQ0U+RxRpf7c6bIOk7rCv2omUvGL2RE4nJako7NJwGdom7f+eCtDyTkYxDePV9vfadHj4mYjCGe8H31NJivN0xsPUL0xldxIYr9oqsSWvSKuLi2zUtiboO0uU9IbhJFBKeReANwK4vzl4FKWUVyKcPFxKeR7A2wD8DoBvrbX+5KiMdu5Az901QhLpdVCO9qRXl5QTvVRfSwSknouu5wJKYcKpfCdS80TYC8hJIrNTQ9zkw2Kr5pX6cRs38Gx9ncqideBFgq85dyCXz+B+aR8X11GJQ+7D55Bkjo3g/LeNFehhlNeMOvDXALxBrtmTh0spX4aTk4n/i80zf6mU8rLtqrywsPAoMZQEaq0/U0p5Ui6/Gf7k4TcD+OFa678H8CullI8C+EoA/0+vjHYqMWPGugz4mT4ZZ1QUbrhx48aZk3NcPmqQ6W0+AWRCUaq320KcV/PkL9fVP8HtTMMiau957jPuS21HEm173Adn9WajsJ7Y7IytTqJzcIY5hjNAJ7IQv7Na67AfeVyxmqdSnZO2dBy63/x3z+jscFGbwPVa6wsAsDlz8Nrm+hMAfpbSHW+uddHUgaQLJnYY6/illKH1VQeLGzyJuaax5FxP7miXviF5OVRs5Pa5iZDbpPaPkVsq6fhHR3kLsJ64zH29t7dn26HBNjOqgQsTZrJST+xPahbfT14UPXuBCVhpMuMArcTV13fkxh63m8dVUje0/clVPFpMX2rDoLOMWR9kKeXtAN7+Epe/sLCwJS46CaSTh48B8FS1B+DXXQZ8KjGfQOQ48sfHx9Ho51YMFtvUx+qswgq+ngg6PNur0a7dd4bBBs1vdOKNbh7pxNnk90803GQU075JfPmWt5MQkurF9QLGYjdDpRhOk0hSzmjLfaDtdu/M0aY5Uo+Nw9xuNfi5MO9e/IQjkzneikLzfFiSwHvhTx5+L4C/WUo5APAlAF4H4J+OMrt79+45sTbpiypiuQ5Ufd/ppvrxcrnODcVIOmXPndXgmG3pqPNefq7d6WWngZMmxUQ0Sm11g5X7jjcFTfXsWbCTeJ/eE9sW0jkPSYVyZfPE4OL9kxqbGKfqgeJ6cfuciuomZ0WaNBJmXIR/CydGwFeVUo4B/G84+fjPnTxca/3FUsqPAPglnJxU/M211t8Z1mJhYeHSMOMd+IZw6/Uh/fcC+N6LVCat8nrPXVPrslt5ej7nkUFNRWRHbknSC6/+zguRNjp1oa3tt/MIjFQQ4PwmpU796tF/uayUp94/Pj62JJyeRT1JNYnnweW3MlRacOlnRHa+rwZBzUOp3smY7OjxrYz2nPOEaFv1uQZH6459uguxA88++2y9fft294jnkfsvdVo6wbf93fJ0HPgkLs/EjKtLr4EHWdojQPNxZc7o+25CGJWj6MXQN7hAl14Ak6vPbOxAKmsmVNr1R9LJ3XjQUG0Xj+Hyb/XlNqSgJEba08BNVLovAaen97diBxYWFs5jJySB0anEM2J7TxRO0XxuFUrlppVbLfK9evZEzyRZpPayeJ0oz6nuXIfRTjnaH65vOQ/2s7u8U0SclsnXRvwPhoraI76ISiCcj5apm79ovVMftbpsY/x1dbkIpKzdDSXm3YYbUsfOfPgznTYjOt+8efMMw26kViicnpY+qFQXp1LMsOK0rWmiGNWHkWIZOK9RO7R/naid2qrWducS5rolq3pP1dD2cR48WSePjj6bJhgXRMXg/SNScFU6l1DT04a9Sx1YWFg4j52QBJo60BOZtjH2sFjaM765QxsTzVJXf73Xnm1wBip9Phm2XJmJ2MN/a1ud9KTlj0JaOV/umyRaz6y8qV4uvkHjBXo+/ZZ+tBtU712m9A1Oikqh2q5uwPnVX8lD7f8RCcvd0/pKubt/7kDi5/deQkrP4pETFff3961op3AulqTbz6gIjvDDdenpvekDc/VSUVS59ooUs6D56KLRm9hGln/tozQJsdtxpNbwBKLpufwZtaz97VQyLluDy5KXyrmCOX2amJQBmya5tPXZiDC01IGFhSuOnVAH3DFkM754xWiv+iQG9kJge5bxhqRK6OqbyB2OMq159Lj92xhH00qSJJBeu7WcFO2p5cwabrWMGQJN4oXMcEpYcnAHkqqqluri6t7rm5HRd/QOHMKYWIbBhYWF89gpSSCtUjN6kN4fBR8xeJVQ3S25xEZRXcnA6BhvI0OW1lFXobTHIbfbpVEfeEPvgNRUt4bEkGvoSTQuerLnumQXYZLkRvXldI4x2GMmcn7ufTyIRJpcqcrFaOAIx2RE/qzjCSTM7ITTQzIkupeo4bujCSfRR5MhbFsSCOeXjEANM1ZyzTN9VJzWkY7cwbFsDDw4OLCn+LR0vevcLq1Xeh/cjobZd6ZeJW0vf4wvlaqWDnd1E8K2EE7CUgcWFhbOY6dchCrGuN8MjbIbBf4cHh6eMc449xvgo8NaPVydR1FebsWfXTFS3d2W1FrfkaEwrewcb8/Pud+ch67evJom92mqe3qvLt6ey75x40asJ/9Wl2iDSlVMf+b7h4eHdozNsCM1DR8bz9IToydhap5a9shFuNPqwIyF2r3kHkYiJNAnx3CZLb8R4ealqmNKm15yagfbP5iqO9MOJUalzUB6urzm2/JzNFldGFy0oNJw3XWtc+ItKCdgb2/vtF6qdzsehJbpIjzTDlBcJ1ZFE8ejF0rM5S91YGFhoYudkgR6ft2GHpMw+fcbJJhiaqVKRj1+LtE+VdS9iL+3QY1rLK4mI57W0yGpJLzKuf0P0wrnfOHJmJvUOa1rkkScF6e374IzMI7exww/hMtPvImk0iYPSY8azv3dwOO5U9bu0obbuQMzL18xsrwnvb/3LP8942bjwTjaVWZmkwlnpVfLONfdqQ89yziXw4PLiZ0qAvd2AEouMRbR9X24kGjNw31IGqrsPALtGeD8phvOO+DUgcPDQ3uf6zmj5iXPSYpS7BGI3DjshYtrfRVLHVhYuOLYKXUA8Ns7M2b8rSoiu5VVuQFu5k3W1x71ticaa5nJyuvap/VLBrIk3ru29n47ycuJvzMx/vqb83B9quLxKDJR65rea+IYjCTOkecmUcAT9yKpvb1Aq5FhdUaK/qwhCznRdtYmwHmk5x0SCSV5B9T9NcNu69VjxpKedj/SfLgsNwnoIEs7ATkykpuYk2tqZgLVD3Qb3XiGx5+uM3pnNbg2j7xIml8Kjx5FQ6bx3FM9kreEcDHvQCnlXaWU+6WUD9G1Hyil/PNSyi+UUn68lPKFdO/5UspHSykfKaV87Sj/hYWFy8VQEiilfBWA/w/AX6ejyb8GwD+qtX66lPL9AFBr/a7NqcR/CyeHkH4JgH8I4PePzh5oJxD1/OJuZuvFFOhzwNyqAowNkmqBTvRRzU994W7m7q08jJHnRNvB13iVSxZrV35vo4sGdzgIY0YsHklFo/SJEsx1dKqmM8ypNJhUDbdv4mxEo/ZPy3/k7UpIZSFIAlPqwOZU4r/XJgG59ycB/A+11udKKc8DQK31L2zu/SSA76m1dk8l5o1Gt3ULputObAMuFm+gZehOMnw/MR57SJbxGRdl2tWmZ09guHQz22M7YtGMlZzbwhNC2r8w5T9T1qwLUuulmCnH1XFEHuulT5NDL2CNr4fJ+qGRhb4RwN/f/H4CAPuZpk4lXlhYuDw8EE+glPLdODlu7D3tkkk2PJX4iSeeOJ29nAjEM6TOyiMjnoqfI/G+t8K0mZdFXZVAuA5qEVd1wVmoWYR0PmnXvhF6qz/nOYpBODz8DF8+GSZZWmpgbw33L6dh8ZrzUS4Bl8X9x2oIGztbWSym9wzFTqXiNs348bnualB2SLTgxEkYoUeJd7jwJFBKeSuANwJ4ff2MTnHhU4mBs1t8z+q3DsomY7jnb970Z8oDZ8XfkatKy+HB4OrMhJEGJrWk52Y+fK2Lg4rLLZ3WPU14nE8DT9ZJp23pVS9PblcX0MWT1tHRkT0tmL0fPDnM7FjlxgP/5n7hvuvFUvBvNw70uuvvVJ9U/xlcSB0opbwBwHcBeFOt9d/RrfcCeEsp5XNLKa/F5KnECwsLl4cZ78DpqcQA7uHkVOLnAXwugE9ukv1srfV/2aT/bpzYCT4N4NtrrX9f8zRl2ErMWt2Bi22ikXbG3cbQlQySzrPQs4xzLEBDIu30eAUji7Lml1QDZ/EH+qtoklYSNTfVl5/vWcnTu0w++FTn3m5IPb5Kkh6TN8iVqfXl/LkuaeOWBs4/HVyC4B246KnEP9RJv/WpxBw7kMQkpzcltlp7Jl1rcJNGiqXvWXpZl+X7WgflrHPdEjvSfTzqekpW/RQzz3m6Z/U9OD04hTs7rj6DRXQXZ9HgVK/kLVHPAqdxHh0um0k8qV29id1hZDtq9XH1ZXDdXRrdXr1Byx1NhCt2YGHhimMnogi3Ac9qswayZGUd+Zxnrcguuo+fT37jxNVPRjc2PnH6JNFwPdLq7/og+ey5nLYKpXBZ9TY4UT95SBROXFdPRJL8Wv7Jp850aW43vzsnpqdNWFweihQGnVZwfWctjRq/0/tLakvDzk4CLDYCsB3LIrW6+RjuZag1XMt26V2eM7obw3kbOJ+enSOJ9K4uShhJYu6MR4AHV4PTOVUHH+3itI1rzPWBY3zqOHAfarKpuMmE89A2cX8llmLqA+5Trr+zxaQwZH2Xrg4zu0UvdWBh4Ypj56IIE5JoNTJ6MHqzYlpl06yeJIFE/23XRvsHjqz+DaOQ5NZeIHMPtNykEvWs5ynke6ZNrl2aRld+3UgDOL8ZKIPrng6gdenTe0xqBT+f4itc+a1u2l71eGhenLZdSxIv5b+7Ows5pEHZ+zBGuk8KFNL800fLKokTt0ZMrZ6+6ERg3ZPA1TfleXh4eObA1W0IRsqGayoOt5t3w0kYudDYMq677bgPSfdOGE3o/EFqH6QPT1UfVbE4UGhEtGIcHR2dc/+2srl8ZVG2NDw5ufxVjWSVYfRdLHVgYeGKYyckgcYTAHJ470gq4L911mfxyW0EwbOoqgwjAtKMeuFWjESaYSSyC69ILApr+K4L650xPKbVw9Un+fo1QjD5/Rt6fANuz0iiSWpTMuxyWWmlTFyDtrKzeJ88RTM7MAGw/I+kDvQ2ZWlIUhVjJyaB69evnw5s95JnCBrJMs5BJCzuMVTXdOUmRqLGoLsBlSy+7kPjyanntXC2ihm9PsXYp228kl2kgXXttPNxmkhZ3dLr21jJk61FF4KRbcbtT+Fcm6N28bNpok97OrjJJE1gvd2zRu+bsdSBhYUrjp31DqhxKlmoHe+6N5vPkIUuYvlv13tGGF5p0t52nMe2K8/Mxhztb+Ds6To9jn7PKzKzcUdqEbY2jgAACWBJREFUq6Zz5QNeneL0SfVIG3dqHRqSNMQYvdfEq+AYgdnTo5M6MPKEpDbhs8E7kNxRypVv0DjyhsQld+W1NL06tbKY5DIjCjawRb1dV3UgTUhuQKWPaG9vzw50/Xi3DVF23gfWkxmODXh8fGx1YC3P2XHcwS6aD+CDzWYnAP44XVyDy4PzUX08EYec/YTbweO/N7E4ohaHUCciUxqzSx1YWLji2Al1wO0xCPRJJqM0MxyAkcFRyxxRb/W35tPbL48xsoynuvfaN1J9VJR3EoLzqKgI7SS51B+MGXUrQXf8SWG3rCbws44ANNNHM6K71hPAubiBkYrBdZ4Jl+88u7vnDrRJQDu+90G56068T8+mQcfoWdtduYr0chu2YQ3OuHoAf2RXsqkkpOAYp+9ynZJOrXYFJ3KreD+y0ej1md9c7owtolcv7Ytkh0juYb4/2touXe8h9Nk6lXhhYeE8dsIweP/+/dNZeEQK2naXmzSDqhg2s5K4+rS8gHxIplvNe5KLq3Mi8KjE1PMvtzTOk8L5qMHVletWvhlJpeWpdemVOdq3T6UVVw+N1nNGWQe16rtNYVyIdQOL/skDlAhUI6rwDGYk3p1QB9hFuI3rhsXMxKriZ7YV+1N9LqJWtPspv7Q9FsMNRv14RsSdnms0tTlNGtqm3nvivGdUk9E4mEmj90d2Ea2r3h/FHrTnky3GlZHqktKom7lBx8RSBxYWFqaxU5LAzKyYDGszzzKSr78nacxYcfVee1aRjFx8j/kRKR4ioWfQ24b0lDYMdc/1JAFnYec6JKkkGUR1TIw2/ujFMjjjnXvvPcnC+ehbnpoPQ42EzgM0azCfUC+XJLCwsHAeaxJYWLjimDl34F04OWnovh5IWkr5DgA/AOCLa62/sbn2PIC3AfgdAN9aa/3JYSWWYXAZBgd10Pxn0izD4Jxh8EJHk2+u3wDwgwD+IIBnaq2/cdGjyZ1NIA3Qnotw5NrTtBd1EaY6PUwXodbRpddneWJxxCHAuwi5TclFyGUkHZ+vJbbljItwJq4+6fgNaQLp2TgakotQ6wGct924bczSYqBIW6BtA2E5XswmUGv9GQC/aW4dAvhOnD1w9M0AfrjW+u9rrb8C4KM4mRAWFhZ2FBciC5VS3gTgE7XWD8pq/ASAn6W/p44m5xOIHHjWnAlJ5b9TGrW0OzLQjLicyCzuWY7oSpuUJHGytz8h/z3isCdyjEoQzMXfhjY88loAOEPf5X0FWz9q3yV1i8k6bmXnvlS68qy6yLsG7e/vx75o1/UsACYPuTHZow2PxmEPjsiUsPUkUEp5BYDvBvA17ra5Njya/PHHHwdwtrHpY2Bwmp6ex3ADJ6XVMrcNIHLqwGibLcAHEOlgGtkq3ASkdeSy0+aUBwcH9oNnkXsm0IUnMMf0TO7PXj816O5OfLI19707uZjVI7cfQnKXHh7OBRDxM6w2jtrNYyWpUwnbBh9dxDvw+wC8FsAHSykfx8nx4+8vpfwebHk0ea312Vrrsy9/+csvUI2FhYWXAltLArXWuwCutb83E8GzG8PgewH8zVLKAU4Mg1NHk3PsAM9aTJpJ4r1bNXsW+5GaoPd4NWfRNRmZegaf3u49nJcTD3mvxFT3dK7CjIGTVRV9luGkFrdSAudDdjUNr7xqsGzl8srKhlfdR3JE7uH3pas1hx73DOW6kroQZL6eNhVREtMIrIYkslzadHRGjbjQ0eS11h+i+x/HZhLY/P2SHE2+thdb24s1rO3FLnl7sXA0Od9/Uv7e+mjyhYWFy8OuxA78KwD/FsBvXHZdDF6FVa9Z7GKdgFWvht9ba/1ivbgTkwAAlFJuO1HlsrHqNY9drBOw6jXCih1YWLjiWJPAwsIVxy5NAu+87AoErHrNYxfrBKx6dbEzNoGFhYXLwS5JAgsLC5eAnZgESilvKKV8pJTy0VLKOy6pDjdKKf9XKeXDpZRfLKV82+b695RSPlFK+cDm39dfQt0+Xkq5uyn/9ubaK0sp/6CU8i83/3/RI67TH6A++UAp5bdLKd9+Gf1VSnlXKeV+KeVDdC32Tynl+c1Y+0gp5WsfYZ1+oJTyz0spv1BK+fFSyhdurj9ZSvkU9dlfeRh1iqi1Xuo/AC8D8DEAXwrgMQAfBPBll1CPVwP4is3vxwH8CwBfBuB7AHzHJffRxwG8Sq797wDesfn9DgDff8nv8P8F8Hsvo78AfBWArwDwoVH/bN7pBwF8Lk5iYD4G4GWPqE5fA+BzNr+/n+r0JKd71P92QRL4SgAfrbX+cq31RQA/jJN9CR4paq0v1Frfv/n9bwB8GBNh0JeINwN49+b3uwH8iUusy+sBfKzW+quXUXj1e16k/nkke164OtVaf6rW+unNnz+LkwC7S8cuTAJPAODIlak9CB4mSilPAvjDAH5uc+nPbUS4dz1qsXuDCuCnSil3NiHYAHC91voCcDKBgYK6LgFvwcmOUg2X3V9A7p9dGW/fCIDjal5bSvlnpZR/XEr5Y4+yIrswCUzvQfAoUEr5fAB/FyfBT78N4C/jJHz6DwF4AcD/cQnV+qO11q8A8HUAvnmz5dtOoJTyGIA3Afg7m0u70F89XPp42wTZfRrAezaXXgDwmlrrHwZwEyeRuF/wqOqzC5PA9B4EDxullN+FkwngPbXWHwOAWuu9Wuvv1Fr/I4C/ikvYLq3W+uub/+8D+PFNHe6VUl69qferAdx/1PXa4OsAvL/Wem9Tx0vvrw1S/1zqeCulvBUnG/c+VzcGgY1q8snN7zs4sVP8/kdVp12YBH4ewOtKKa/drCpvAfDeR12JchLf+UMAPlxrPaDrr6ZkfxLAh/TZh1yvzyulPN5+48S49CGc9NFbN8neCuAnHmW9CN8AUgUuu78IqX/eC+AtpZTPLaW8FpN7XrwUKKW8AcB3AXhTrfXf0fUvLqW8bPP7Szd1+uVHUScAl+8d2EyGX48Ta/zHAHz3JdXhv8GJWPgLAD6w+ff1AP4GgLub6+8F8OpHXK8vxYk1+4MAfrH1D4DfDeB9AP7l5v9XXkKfvQLAJwH8Z3TtkfcXTiahFwD8B5ys9G/r9Q9Otsf7GICPAPi6R1inj+LEHtHG11/ZpP1Tm3f7QQDvB/DfP8r3uBiDCwtXHLugDiwsLFwi1iSwsHDFsSaBhYUrjjUJLCxccaxJYGHhimNNAgsLVxxrElhYuOJYk8DCwhXH/w/ebODiysiYpgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import imageio\n",
    "from matplotlib import pyplot as plt\n",
    "import imageGeneration\n",
    "\n",
    "i = 16\n",
    "\n",
    "im = imageio.imread('data/particles/train/image/' + str(i) + '.png') / 255\n",
    "plt.imshow(im, cmap='gray')\n",
    "plt.show()\n",
    "im = imageGeneration.get_image_with_padding(im)\n",
    "plt.imshow(im, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "im = imageio.imread('data/particles/train/label/' + str(i) + '.png') / 255\n",
    "plt.imshow(im, cmap='gray')\n",
    "plt.show()\n",
    "im = imageGeneration.get_image_with_padding(im)\n",
    "plt.imshow(im, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
